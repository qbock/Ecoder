{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-02 07:18:47.311357: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:18:47.311395: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "(45796, 4, 4, 3)\n",
      "(45796, 4, 4, 3)\n",
      "(45796,)\n",
      "(46225, 4, 4, 3)\n",
      "(46225, 4, 4, 3)\n",
      "(46225,)\n",
      "2021-07-02 07:19:01.645256: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 07:19:01.646667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-02 07:19:01.721974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:da:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.73GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-02 07:19:01.722146: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:19:01.722212: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:19:01.722262: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:19:01.722318: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:19:01.722371: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:19:01.722425: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:19:01.722482: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:19:01.722537: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 07:19:01.722551: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-02 07:19:01.723167: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-02 07:19:01.733088: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 07:19:01.733207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-02 07:19:01.733245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 4, 4, 6)      0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 4, 32)     4832        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_1 (BatchNormalization (None, 4, 4, 32)     128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_1 (Activation)             (None, 4, 4, 32)     0           batchnorm_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 32)     25632       relu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_2 (BatchNormalization (None, 4, 4, 32)     128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_2 (Activation)             (None, 4, 4, 32)     0           batchnorm_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 32)     25632       relu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_3 (BatchNormalization (None, 4, 4, 32)     128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3 (Activation)             (None, 4, 4, 32)     0           batchnorm_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           relu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm4 (BatchNormalization) (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_4 (Activation)             (None, 256)          0           batchnorm4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            257         relu_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 189,089\n",
      "Trainable params: 188,385\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sym_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         (None, 1)            189089      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 1)            0           base_model[0][0]                 \n",
      "                                                                 base_model[1][0]                 \n",
      "==================================================================================================\n",
      "Total params: 189,089\n",
      "Trainable params: 188,385\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "2021-07-02 07:19:02.047677: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-02 07:19:02.048138: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\n",
      "Epoch 1/50\n",
      "1432/1432 [==============================] - 38s 25ms/step - loss: 0.1824 - mse: 4.3797 - mae: 1.2402 - mape: 13423391.3010 - msle: 0.1453 - val_loss: 0.0323 - val_mse: 0.3352 - val_mae: 0.4391 - val_mape: 4117047.0000 - val_msle: 0.0106\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03233, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00001: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 2/50\n",
      "1432/1432 [==============================] - 35s 25ms/step - loss: 0.0300 - mse: 0.4167 - mae: 0.5032 - mape: 3777509.9650 - msle: 0.0116 - val_loss: 0.0385 - val_mse: 1.1032 - val_mae: 0.9328 - val_mape: 1658862.3750 - val_msle: 0.0274\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03233\n",
      "\n",
      "Epoch 00002: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 3/50\n",
      "1432/1432 [==============================] - 35s 25ms/step - loss: 0.0194 - mse: 0.3734 - mae: 0.4736 - mape: 2686533.2955 - msle: 0.0095 - val_loss: 0.0158 - val_mse: 0.2810 - val_mae: 0.4219 - val_mape: 3465450.0000 - val_msle: 0.0086\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03233 to 0.01577, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00003: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 4/50\n",
      "1432/1432 [==============================] - 35s 25ms/step - loss: 0.0160 - mse: 0.3612 - mae: 0.4646 - mape: 2888903.9084 - msle: 0.0093 - val_loss: 0.0120 - val_mse: 0.2139 - val_mae: 0.3598 - val_mape: 2588108.0000 - val_msle: 0.0063\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01577 to 0.01204, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00004: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 5/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0149 - mse: 0.3625 - mae: 0.4673 - mape: 2623409.5141 - msle: 0.0093 - val_loss: 0.0092 - val_mse: 0.1510 - val_mae: 0.3009 - val_mape: 1788630.2500 - val_msle: 0.0044\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01204 to 0.00917, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00005: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 6/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0141 - mse: 0.3508 - mae: 0.4577 - mape: 2374846.3120 - msle: 0.0090 - val_loss: 0.0105 - val_mse: 0.2335 - val_mae: 0.3712 - val_mape: 784309.9375 - val_msle: 0.0058\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00917\n",
      "\n",
      "Epoch 00006: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 7/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0126 - mse: 0.3226 - mae: 0.4390 - mape: 2037896.1028 - msle: 0.0079 - val_loss: 0.0126 - val_mse: 0.3549 - val_mae: 0.5039 - val_mape: 557288.6250 - val_msle: 0.0081\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00917\n",
      "\n",
      "Epoch 00007: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 8/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0122 - mse: 0.3141 - mae: 0.4316 - mape: 1970674.6004 - msle: 0.0078 - val_loss: 0.0099 - val_mse: 0.1738 - val_mae: 0.3304 - val_mape: 1731757.7500 - val_msle: 0.0054\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00917\n",
      "\n",
      "Epoch 00008: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 9/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0117 - mse: 0.2982 - mae: 0.4212 - mape: 1600707.1627 - msle: 0.0073 - val_loss: 0.0076 - val_mse: 0.1189 - val_mae: 0.2652 - val_mape: 1089742.2500 - val_msle: 0.0036\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00917 to 0.00760, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00009: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 10/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0106 - mse: 0.2733 - mae: 0.4054 - mape: 1753725.1918 - msle: 0.0067 - val_loss: 0.0135 - val_mse: 0.4881 - val_mae: 0.5995 - val_mape: 1473835.3750 - val_msle: 0.0099\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00760\n",
      "\n",
      "Epoch 00010: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 11/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0103 - mse: 0.2707 - mae: 0.4034 - mape: 1781613.0645 - msle: 0.0067 - val_loss: 0.0067 - val_mse: 0.1217 - val_mae: 0.2669 - val_mape: 1496958.1250 - val_msle: 0.0033\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00760 to 0.00667, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00011: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 12/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0104 - mse: 0.2833 - mae: 0.4082 - mape: 2015717.9970 - msle: 0.0070 - val_loss: 0.0099 - val_mse: 0.3047 - val_mae: 0.4352 - val_mape: 994219.8125 - val_msle: 0.0066\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00667\n",
      "\n",
      "Epoch 00012: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 13/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0098 - mse: 0.2666 - mae: 0.3986 - mape: 1744020.1052 - msle: 0.0066 - val_loss: 0.0071 - val_mse: 0.1343 - val_mae: 0.2787 - val_mape: 1664079.5000 - val_msle: 0.0041\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00667\n",
      "\n",
      "Epoch 00013: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 14/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0094 - mse: 0.2540 - mae: 0.3898 - mape: 1784354.9594 - msle: 0.0063 - val_loss: 0.0081 - val_mse: 0.1670 - val_mae: 0.3186 - val_mape: 1095437.0000 - val_msle: 0.0049\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00667\n",
      "\n",
      "Epoch 00014: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 15/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0089 - mse: 0.2518 - mae: 0.3851 - mape: 1353025.1081 - msle: 0.0059 - val_loss: 0.0150 - val_mse: 0.4709 - val_mae: 0.5780 - val_mape: 1685391.3750 - val_msle: 0.0120\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00667\n",
      "\n",
      "Epoch 00015: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 16/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0093 - mse: 0.2552 - mae: 0.3902 - mape: 1764234.7660 - msle: 0.0063 - val_loss: 0.0077 - val_mse: 0.2016 - val_mae: 0.3615 - val_mape: 2470494.5000 - val_msle: 0.0048\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00667\n",
      "\n",
      "Epoch 00016: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 17/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0085 - mse: 0.2468 - mae: 0.3818 - mape: 1313768.8709 - msle: 0.0058 - val_loss: 0.0099 - val_mse: 0.2400 - val_mae: 0.4029 - val_mape: 2290997.2500 - val_msle: 0.0072\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00667\n",
      "\n",
      "Epoch 00017: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 18/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0087 - mse: 0.2440 - mae: 0.3815 - mape: 1708266.9828 - msle: 0.0060 - val_loss: 0.0063 - val_mse: 0.1139 - val_mae: 0.2542 - val_mape: 2274563.7500 - val_msle: 0.0035\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00667 to 0.00632, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00018: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 19/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0084 - mse: 0.2355 - mae: 0.3742 - mape: 1717484.3291 - msle: 0.0057 - val_loss: 0.0064 - val_mse: 0.1407 - val_mae: 0.2887 - val_mape: 2336963.0000 - val_msle: 0.0039\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00632\n",
      "\n",
      "Epoch 00019: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 20/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0088 - mse: 0.2542 - mae: 0.3877 - mape: 1773681.7488 - msle: 0.0062 - val_loss: 0.0065 - val_mse: 0.1463 - val_mae: 0.2904 - val_mape: 2052148.3750 - val_msle: 0.0040\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00632\n",
      "\n",
      "Epoch 00020: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 21/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0087 - mse: 0.2498 - mae: 0.3867 - mape: 2033428.6865 - msle: 0.0062 - val_loss: 0.0063 - val_mse: 0.1446 - val_mae: 0.3037 - val_mape: 1558305.0000 - val_msle: 0.0039\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00632\n",
      "\n",
      "Epoch 00021: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 22/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0083 - mse: 0.2395 - mae: 0.3794 - mape: 1653341.7733 - msle: 0.0058 - val_loss: 0.0104 - val_mse: 0.3424 - val_mae: 0.4867 - val_mape: 1249462.2500 - val_msle: 0.0080\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00632\n",
      "\n",
      "Epoch 00022: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 23/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0081 - mse: 0.2277 - mae: 0.3689 - mape: 2062029.4847 - msle: 0.0057 - val_loss: 0.0058 - val_mse: 0.1354 - val_mae: 0.2800 - val_mape: 1614042.1250 - val_msle: 0.0035\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00632 to 0.00580, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00023: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 24/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0084 - mse: 0.2428 - mae: 0.3796 - mape: 1615618.7120 - msle: 0.0060 - val_loss: 0.0058 - val_mse: 0.1106 - val_mae: 0.2502 - val_mape: 1402093.7500 - val_msle: 0.0033\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00580 to 0.00580, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00024: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 25/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0078 - mse: 0.2195 - mae: 0.3626 - mape: 1590880.3760 - msle: 0.0054 - val_loss: 0.0166 - val_mse: 0.5805 - val_mae: 0.6388 - val_mape: 1991863.0000 - val_msle: 0.0143\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00580\n",
      "\n",
      "Epoch 00025: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 26/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0088 - mse: 0.2478 - mae: 0.3843 - mape: 2039202.6411 - msle: 0.0064 - val_loss: 0.0057 - val_mse: 0.1276 - val_mae: 0.2714 - val_mape: 1819268.5000 - val_msle: 0.0034\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00580 to 0.00572, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00026: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 27/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0085 - mse: 0.2483 - mae: 0.3843 - mape: 1954467.3259 - msle: 0.0062 - val_loss: 0.0071 - val_mse: 0.2198 - val_mae: 0.3537 - val_mape: 1836699.2500 - val_msle: 0.0047\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00027: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 28/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0082 - mse: 0.2480 - mae: 0.3835 - mape: 1703334.6873 - msle: 0.0059 - val_loss: 0.0105 - val_mse: 0.3875 - val_mae: 0.5167 - val_mape: 2149418.7500 - val_msle: 0.0082\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00028: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 29/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0078 - mse: 0.2277 - mae: 0.3690 - mape: 1810861.9879 - msle: 0.0056 - val_loss: 0.0102 - val_mse: 0.3219 - val_mae: 0.4790 - val_mape: 1913469.7500 - val_msle: 0.0080\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00029: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 30/50\n",
      "1432/1432 [==============================] - 35s 25ms/step - loss: 0.0075 - mse: 0.2185 - mae: 0.3592 - mape: 1789637.6565 - msle: 0.0053 - val_loss: 0.0058 - val_mse: 0.1289 - val_mae: 0.2663 - val_mape: 706164.1250 - val_msle: 0.0036\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00030: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 31/50\n",
      "1432/1432 [==============================] - 35s 25ms/step - loss: 0.0076 - mse: 0.2165 - mae: 0.3606 - mape: 1419487.7731 - msle: 0.0053 - val_loss: 0.0077 - val_mse: 0.1693 - val_mae: 0.3142 - val_mape: 2275889.7500 - val_msle: 0.0054\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00572\n",
      "\n",
      "Epoch 00031: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 32/50\n",
      "1432/1432 [==============================] - 35s 25ms/step - loss: 0.0081 - mse: 0.2381 - mae: 0.3741 - mape: 1599093.9775 - msle: 0.0059 - val_loss: 0.0057 - val_mse: 0.1254 - val_mae: 0.2574 - val_mape: 2222530.5000 - val_msle: 0.0034\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00572 to 0.00567, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00032: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 33/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0075 - mse: 0.2228 - mae: 0.3631 - mape: 1642302.2302 - msle: 0.0053 - val_loss: 0.0064 - val_mse: 0.1535 - val_mae: 0.3152 - val_mape: 2442191.5000 - val_msle: 0.0043\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00567\n",
      "\n",
      "Epoch 00033: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 34/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0085 - mse: 0.2482 - mae: 0.3871 - mape: 2017909.1612 - msle: 0.0063 - val_loss: 0.0064 - val_mse: 0.1639 - val_mae: 0.3183 - val_mape: 1244237.2500 - val_msle: 0.0042\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00567\n",
      "\n",
      "Epoch 00034: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 35/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0078 - mse: 0.2278 - mae: 0.3694 - mape: 1855778.0215 - msle: 0.0056 - val_loss: 0.0056 - val_mse: 0.1290 - val_mae: 0.2703 - val_mape: 1358548.2500 - val_msle: 0.0035\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00567 to 0.00563, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00035: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 36/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0079 - mse: 0.2362 - mae: 0.3760 - mape: 1657892.7530 - msle: 0.0058 - val_loss: 0.0056 - val_mse: 0.1256 - val_mae: 0.2751 - val_mape: 1614362.0000 - val_msle: 0.0035\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00563 to 0.00562, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00036: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 37/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0072 - mse: 0.2157 - mae: 0.3564 - mape: 1487415.1608 - msle: 0.0051 - val_loss: 0.0077 - val_mse: 0.2255 - val_mae: 0.3925 - val_mape: 1355183.2500 - val_msle: 0.0056\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00037: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 38/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0074 - mse: 0.2198 - mae: 0.3624 - mape: 1622888.8669 - msle: 0.0052 - val_loss: 0.0132 - val_mse: 0.4325 - val_mae: 0.5729 - val_mape: 1773813.5000 - val_msle: 0.0111\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00038: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 39/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0072 - mse: 0.2067 - mae: 0.3517 - mape: 1644877.0524 - msle: 0.0051 - val_loss: 0.0163 - val_mse: 0.6682 - val_mae: 0.6857 - val_mape: 1874665.6250 - val_msle: 0.0142\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00039: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 40/50\n",
      "1432/1432 [==============================] - 35s 25ms/step - loss: 0.0075 - mse: 0.2132 - mae: 0.3612 - mape: 1785989.1734 - msle: 0.0053 - val_loss: 0.0058 - val_mse: 0.1275 - val_mae: 0.2790 - val_mape: 1334058.5000 - val_msle: 0.0037\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00040: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 41/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0076 - mse: 0.2220 - mae: 0.3633 - mape: 1674144.3874 - msle: 0.0055 - val_loss: 0.0058 - val_mse: 0.1279 - val_mae: 0.2617 - val_mape: 1885024.2500 - val_msle: 0.0037\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00041: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 42/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0075 - mse: 0.2161 - mae: 0.3617 - mape: 1847733.4347 - msle: 0.0054 - val_loss: 0.0072 - val_mse: 0.2377 - val_mae: 0.3897 - val_mape: 1263981.8750 - val_msle: 0.0051\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00042: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 43/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0076 - mse: 0.2274 - mae: 0.3681 - mape: 1725412.1425 - msle: 0.0055 - val_loss: 0.0062 - val_mse: 0.1543 - val_mae: 0.2991 - val_mape: 3415921.2500 - val_msle: 0.0041\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00043: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 44/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0075 - mse: 0.2210 - mae: 0.3640 - mape: 2007748.0233 - msle: 0.0054 - val_loss: 0.0062 - val_mse: 0.1568 - val_mae: 0.3003 - val_mape: 2518723.7500 - val_msle: 0.0041\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00044: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 45/50\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0077 - mse: 0.2305 - mae: 0.3708 - mape: 1863848.5207 - msle: 0.0056 - val_loss: 0.0069 - val_mse: 0.2088 - val_mae: 0.3506 - val_mape: 2049827.1250 - val_msle: 0.0048\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00045: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 46/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0077 - mse: 0.2227 - mae: 0.3641 - mape: 1930665.8757 - msle: 0.0056 - val_loss: 0.0125 - val_mse: 0.3617 - val_mae: 0.5193 - val_mape: 1591351.2500 - val_msle: 0.0104\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00046: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 47/50\n",
      "1432/1432 [==============================] - 35s 25ms/step - loss: 0.0076 - mse: 0.2292 - mae: 0.3695 - mape: 1597784.9897 - msle: 0.0054 - val_loss: 0.0056 - val_mse: 0.1277 - val_mae: 0.2655 - val_mape: 1440491.5000 - val_msle: 0.0035\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00562\n",
      "\n",
      "Epoch 00047: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 48/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0071 - mse: 0.2082 - mae: 0.3529 - mape: 1588346.7518 - msle: 0.0050 - val_loss: 0.0047 - val_mse: 0.0896 - val_mae: 0.2220 - val_mape: 1730428.5000 - val_msle: 0.0026\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00562 to 0.00466, saving model to emd_loss_models/3252561350best.h5\n",
      "\n",
      "Epoch 00048: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 49/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0069 - mse: 0.1938 - mae: 0.3425 - mape: 1472236.9113 - msle: 0.0048 - val_loss: 0.0122 - val_mse: 0.5334 - val_mae: 0.6292 - val_mape: 2848786.7500 - val_msle: 0.0101\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00466\n",
      "\n",
      "Epoch 00049: saving model to emd_loss_models/3252561350last.h5\n",
      "Epoch 50/50\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0071 - mse: 0.2141 - mae: 0.3561 - mape: 1671542.2158 - msle: 0.0051 - val_loss: 0.0054 - val_mse: 0.1131 - val_mae: 0.2485 - val_mape: 2133610.2500 - val_msle: 0.0035\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00466\n",
      "\n",
      "Epoch 00050: saving model to emd_loss_models/3252561350last.h5\n",
      "(45796, 4, 4, 3)\n",
      "(45796, 4, 4, 3)\n",
      "(45796,)\n",
      "(46225, 4, 4, 3)\n",
      "(46225, 4, 4, 3)\n",
      "(46225,)\n",
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 4, 4, 6)      0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 4, 32)     4832        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_1 (BatchNormalization (None, 4, 4, 32)     128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_1 (Activation)             (None, 4, 4, 32)     0           batchnorm_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 32)     25632       relu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_2 (BatchNormalization (None, 4, 4, 32)     128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_2 (Activation)             (None, 4, 4, 32)     0           batchnorm_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 32)     25632       relu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_3 (BatchNormalization (None, 4, 4, 32)     128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3 (Activation)             (None, 4, 4, 32)     0           batchnorm_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           relu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm4 (BatchNormalization) (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_4 (Activation)             (None, 256)          0           batchnorm4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            257         relu_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 189,089\n",
      "Trainable params: 188,385\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"sym_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_model (Functional)         (None, 1)            189089      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 1)            0           base_model[0][0]                 \n",
      "                                                                 base_model[1][0]                 \n",
      "==================================================================================================\n",
      "Total params: 189,089\n",
      "Trainable params: 188,385\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/51\n",
      "1432/1432 [==============================] - 36s 25ms/step - loss: 0.2998 - mse: 9.6280 - mae: 1.6352 - mape: 16053188.3710 - msle: 0.2619 - val_loss: 0.0323 - val_mse: 0.3923 - val_mae: 0.4883 - val_mape: 2201704.2500 - val_msle: 0.0099\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03230, saving model to emd_loss_models/3252561351best.h5\n",
      "\n",
      "Epoch 00001: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 2/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0308 - mse: 0.4281 - mae: 0.5127 - mape: 3435111.7737 - msle: 0.0119 - val_loss: 0.0296 - val_mse: 0.7422 - val_mae: 0.7183 - val_mape: 3079110.2500 - val_msle: 0.0186\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03230 to 0.02960, saving model to emd_loss_models/3252561351best.h5\n",
      "\n",
      "Epoch 00002: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 3/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0201 - mse: 0.3782 - mae: 0.4801 - mape: 3276572.9081 - msle: 0.0103 - val_loss: 0.0132 - val_mse: 0.2637 - val_mae: 0.3808 - val_mape: 1562830.8750 - val_msle: 0.0062\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02960 to 0.01324, saving model to emd_loss_models/3252561351best.h5\n",
      "\n",
      "Epoch 00003: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 4/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0151 - mse: 0.3315 - mae: 0.4453 - mape: 2403487.6129 - msle: 0.0087 - val_loss: 0.0272 - val_mse: 0.7961 - val_mae: 0.7541 - val_mape: 3472122.7500 - val_msle: 0.0217\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.01324\n",
      "\n",
      "Epoch 00004: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 5/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0188 - mse: 0.4492 - mae: 0.5066 - mape: 3001646.2432 - msle: 0.0122 - val_loss: 0.0104 - val_mse: 0.1937 - val_mae: 0.3328 - val_mape: 1291640.8750 - val_msle: 0.0055\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01324 to 0.01044, saving model to emd_loss_models/3252561351best.h5\n",
      "\n",
      "Epoch 00005: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 6/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0124 - mse: 0.3070 - mae: 0.4281 - mape: 1552703.9797 - msle: 0.0077 - val_loss: 0.0115 - val_mse: 0.2182 - val_mae: 0.3601 - val_mape: 566781.5000 - val_msle: 0.0066\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01044\n",
      "\n",
      "Epoch 00006: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 7/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0122 - mse: 0.2942 - mae: 0.4202 - mape: 1600563.1977 - msle: 0.0076 - val_loss: 0.0120 - val_mse: 0.2908 - val_mae: 0.4217 - val_mape: 818779.3750 - val_msle: 0.0078\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01044\n",
      "\n",
      "Epoch 00007: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 8/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0115 - mse: 0.2931 - mae: 0.4172 - mape: 1528233.0894 - msle: 0.0073 - val_loss: 0.0104 - val_mse: 0.1903 - val_mae: 0.3300 - val_mape: 1269056.3750 - val_msle: 0.0064\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01044\n",
      "\n",
      "Epoch 00008: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 9/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0112 - mse: 0.2845 - mae: 0.4137 - mape: 1405560.1895 - msle: 0.0072 - val_loss: 0.0072 - val_mse: 0.1296 - val_mae: 0.2678 - val_mape: 515889.1250 - val_msle: 0.0036\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01044 to 0.00724, saving model to emd_loss_models/3252561351best.h5\n",
      "\n",
      "Epoch 00009: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 10/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0109 - mse: 0.2850 - mae: 0.4143 - mape: 1468282.4453 - msle: 0.0072 - val_loss: 0.0095 - val_mse: 0.2279 - val_mae: 0.3713 - val_mape: 473089.6875 - val_msle: 0.0060\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00724\n",
      "\n",
      "Epoch 00010: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 11/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0104 - mse: 0.2740 - mae: 0.4057 - mape: 1351559.2682 - msle: 0.0069 - val_loss: 0.0094 - val_mse: 0.2445 - val_mae: 0.3970 - val_mape: 445558.5000 - val_msle: 0.0063\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00724\n",
      "\n",
      "Epoch 00011: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 12/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0099 - mse: 0.2658 - mae: 0.3957 - mape: 1303350.1716 - msle: 0.0067 - val_loss: 0.0069 - val_mse: 0.1202 - val_mae: 0.2588 - val_mape: 1184566.1250 - val_msle: 0.0039\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00724 to 0.00694, saving model to emd_loss_models/3252561351best.h5\n",
      "\n",
      "Epoch 00012: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 13/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0100 - mse: 0.2704 - mae: 0.4045 - mape: 1349868.8051 - msle: 0.0068 - val_loss: 0.0119 - val_mse: 0.3405 - val_mae: 0.4629 - val_mape: 260898.8906 - val_msle: 0.0088\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00694\n",
      "\n",
      "Epoch 00013: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 14/51\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0089 - mse: 0.2360 - mae: 0.3755 - mape: 1058340.3367 - msle: 0.0059 - val_loss: 0.0078 - val_mse: 0.2287 - val_mae: 0.3681 - val_mape: 433983.3750 - val_msle: 0.0050\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00694\n",
      "\n",
      "Epoch 00014: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 15/51\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0088 - mse: 0.2444 - mae: 0.3823 - mape: 1142196.1172 - msle: 0.0060 - val_loss: 0.0074 - val_mse: 0.2022 - val_mae: 0.3448 - val_mape: 471023.5938 - val_msle: 0.0045\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00694\n",
      "\n",
      "Epoch 00015: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 16/51\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0087 - mse: 0.2304 - mae: 0.3715 - mape: 1282365.1651 - msle: 0.0058 - val_loss: 0.0060 - val_mse: 0.1317 - val_mae: 0.2633 - val_mape: 913504.2500 - val_msle: 0.0034\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00694 to 0.00602, saving model to emd_loss_models/3252561351best.h5\n",
      "\n",
      "Epoch 00016: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 17/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0084 - mse: 0.2329 - mae: 0.3721 - mape: 1225742.7063 - msle: 0.0058 - val_loss: 0.0091 - val_mse: 0.2738 - val_mae: 0.4290 - val_mape: 168357.1562 - val_msle: 0.0065\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00017: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 18/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0083 - mse: 0.2331 - mae: 0.3725 - mape: 1135036.3448 - msle: 0.0057 - val_loss: 0.0150 - val_mse: 0.5002 - val_mae: 0.6115 - val_mape: 1220355.5000 - val_msle: 0.0126\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00018: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 19/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0094 - mse: 0.2625 - mae: 0.3960 - mape: 1477386.8766 - msle: 0.0067 - val_loss: 0.0230 - val_mse: 1.0379 - val_mae: 0.9163 - val_mape: 749895.0000 - val_msle: 0.0204\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00019: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 20/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0087 - mse: 0.2422 - mae: 0.3800 - mape: 1485891.5249 - msle: 0.0061 - val_loss: 0.0070 - val_mse: 0.1677 - val_mae: 0.3166 - val_mape: 830037.2500 - val_msle: 0.0044\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00020: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 21/51\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0083 - mse: 0.2343 - mae: 0.3740 - mape: 1461374.0373 - msle: 0.0057 - val_loss: 0.0072 - val_mse: 0.1618 - val_mae: 0.3080 - val_mape: 1928581.8750 - val_msle: 0.0048\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00021: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 22/51\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0081 - mse: 0.2322 - mae: 0.3744 - mape: 1122612.5132 - msle: 0.0057 - val_loss: 0.0074 - val_mse: 0.1750 - val_mae: 0.3238 - val_mape: 776754.2500 - val_msle: 0.0051\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00022: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 23/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0077 - mse: 0.2119 - mae: 0.3583 - mape: 1351039.0978 - msle: 0.0053 - val_loss: 0.0067 - val_mse: 0.1474 - val_mae: 0.2741 - val_mape: 2002827.1250 - val_msle: 0.0043\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00023: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 24/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0079 - mse: 0.2197 - mae: 0.3644 - mape: 1588707.6573 - msle: 0.0055 - val_loss: 0.0074 - val_mse: 0.1543 - val_mae: 0.2952 - val_mape: 2086859.0000 - val_msle: 0.0049\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00024: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 25/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0078 - mse: 0.2119 - mae: 0.3571 - mape: 1675860.2360 - msle: 0.0053 - val_loss: 0.0325 - val_mse: 1.4840 - val_mae: 1.1306 - val_mape: 2513734.7500 - val_msle: 0.0301\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00025: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 26/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0088 - mse: 0.2343 - mae: 0.3745 - mape: 1866422.2636 - msle: 0.0063 - val_loss: 0.0068 - val_mse: 0.1730 - val_mae: 0.3202 - val_mape: 1965237.0000 - val_msle: 0.0044\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00026: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 27/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0076 - mse: 0.2089 - mae: 0.3535 - mape: 1667874.0879 - msle: 0.0052 - val_loss: 0.0066 - val_mse: 0.1571 - val_mae: 0.3093 - val_mape: 3139886.5000 - val_msle: 0.0043\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00027: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 28/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0087 - mse: 0.2331 - mae: 0.3730 - mape: 2109384.3039 - msle: 0.0062 - val_loss: 0.0108 - val_mse: 0.3463 - val_mae: 0.4776 - val_mape: 2251328.5000 - val_msle: 0.0083\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00028: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 29/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0074 - mse: 0.2026 - mae: 0.3508 - mape: 1687611.6001 - msle: 0.0050 - val_loss: 0.0073 - val_mse: 0.2427 - val_mae: 0.3559 - val_mape: 1031555.0000 - val_msle: 0.0049\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00029: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 30/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0073 - mse: 0.2043 - mae: 0.3506 - mape: 1786154.7468 - msle: 0.0050 - val_loss: 0.0066 - val_mse: 0.1578 - val_mae: 0.3096 - val_mape: 1033296.2500 - val_msle: 0.0043\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00602\n",
      "\n",
      "Epoch 00030: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 31/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0081 - mse: 0.2146 - mae: 0.3588 - mape: 2001749.2207 - msle: 0.0057 - val_loss: 0.0052 - val_mse: 0.1031 - val_mae: 0.2347 - val_mape: 1968920.1250 - val_msle: 0.0028\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00602 to 0.00517, saving model to emd_loss_models/3252561351best.h5\n",
      "\n",
      "Epoch 00031: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 32/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0080 - mse: 0.2147 - mae: 0.3575 - mape: 1850789.8116 - msle: 0.0056 - val_loss: 0.0142 - val_mse: 0.5401 - val_mae: 0.6376 - val_mape: 1763253.3750 - val_msle: 0.0119\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00032: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 33/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0078 - mse: 0.2147 - mae: 0.3569 - mape: 1942245.5991 - msle: 0.0054 - val_loss: 0.0054 - val_mse: 0.1034 - val_mae: 0.2360 - val_mape: 1898469.8750 - val_msle: 0.0031\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00033: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 34/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0072 - mse: 0.1993 - mae: 0.3466 - mape: 2070408.4357 - msle: 0.0050 - val_loss: 0.0056 - val_mse: 0.1202 - val_mae: 0.2551 - val_mape: 2540750.5000 - val_msle: 0.0034\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00034: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 35/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0071 - mse: 0.1990 - mae: 0.3472 - mape: 1797823.3436 - msle: 0.0049 - val_loss: 0.0066 - val_mse: 0.1785 - val_mae: 0.3129 - val_mape: 1686813.5000 - val_msle: 0.0043\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00035: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 36/51\n",
      "1432/1432 [==============================] - 36s 25ms/step - loss: 0.0076 - mse: 0.2124 - mae: 0.3572 - mape: 1993164.7173 - msle: 0.0053 - val_loss: 0.0052 - val_mse: 0.1019 - val_mae: 0.2318 - val_mape: 1944757.7500 - val_msle: 0.0030\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00036: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 37/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0072 - mse: 0.2006 - mae: 0.3474 - mape: 1732235.8152 - msle: 0.0049 - val_loss: 0.0077 - val_mse: 0.2660 - val_mae: 0.4014 - val_mape: 1496535.0000 - val_msle: 0.0054\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00037: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 38/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0077 - mse: 0.2062 - mae: 0.3528 - mape: 1864969.2429 - msle: 0.0054 - val_loss: 0.0071 - val_mse: 0.1483 - val_mae: 0.2878 - val_mape: 2706399.5000 - val_msle: 0.0049\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00038: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 39/51\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0074 - mse: 0.1994 - mae: 0.3469 - mape: 2107786.4167 - msle: 0.0052 - val_loss: 0.0059 - val_mse: 0.1331 - val_mae: 0.2679 - val_mape: 2409455.5000 - val_msle: 0.0037\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00039: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 40/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0074 - mse: 0.2033 - mae: 0.3493 - mape: 1775354.6091 - msle: 0.0052 - val_loss: 0.0064 - val_mse: 0.1901 - val_mae: 0.3305 - val_mape: 1707739.5000 - val_msle: 0.0042\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00040: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 41/51\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0083 - mse: 0.2221 - mae: 0.3645 - mape: 2275740.0882 - msle: 0.0059 - val_loss: 0.0094 - val_mse: 0.2745 - val_mae: 0.4067 - val_mape: 2066210.2500 - val_msle: 0.0071\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00041: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 42/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0072 - mse: 0.1981 - mae: 0.3451 - mape: 1429669.1763 - msle: 0.0050 - val_loss: 0.0075 - val_mse: 0.1984 - val_mae: 0.3364 - val_mape: 2819430.7500 - val_msle: 0.0052\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00042: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 43/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0074 - mse: 0.1972 - mae: 0.3450 - mape: 1824869.3530 - msle: 0.0051 - val_loss: 0.0061 - val_mse: 0.1506 - val_mae: 0.3044 - val_mape: 1874527.0000 - val_msle: 0.0039\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00043: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 44/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0069 - mse: 0.1923 - mae: 0.3404 - mape: 1774038.5474 - msle: 0.0048 - val_loss: 0.0067 - val_mse: 0.2081 - val_mae: 0.3544 - val_mape: 1474366.2500 - val_msle: 0.0044\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00044: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 45/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0070 - mse: 0.1848 - mae: 0.3335 - mape: 1674339.2536 - msle: 0.0048 - val_loss: 0.0072 - val_mse: 0.1956 - val_mae: 0.3502 - val_mape: 1155708.7500 - val_msle: 0.0050\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00045: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 46/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0071 - mse: 0.1900 - mae: 0.3379 - mape: 1450295.6171 - msle: 0.0049 - val_loss: 0.0056 - val_mse: 0.1437 - val_mae: 0.2944 - val_mape: 2526174.5000 - val_msle: 0.0034\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00046: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 47/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0070 - mse: 0.1937 - mae: 0.3415 - mape: 2044513.8948 - msle: 0.0048 - val_loss: 0.0068 - val_mse: 0.1594 - val_mae: 0.3033 - val_mape: 2122054.0000 - val_msle: 0.0046\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00047: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 48/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0068 - mse: 0.1853 - mae: 0.3353 - mape: 1504376.6021 - msle: 0.0046 - val_loss: 0.0108 - val_mse: 0.3902 - val_mae: 0.4956 - val_mape: 1850919.1250 - val_msle: 0.0086\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00048: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 49/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0071 - mse: 0.1858 - mae: 0.3336 - mape: 1660889.5818 - msle: 0.0049 - val_loss: 0.0068 - val_mse: 0.1761 - val_mae: 0.3223 - val_mape: 2075538.2500 - val_msle: 0.0046\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00049: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 50/51\n",
      "1432/1432 [==============================] - 34s 24ms/step - loss: 0.0068 - mse: 0.1732 - mae: 0.3236 - mape: 1844105.0922 - msle: 0.0046 - val_loss: 0.0069 - val_mse: 0.1682 - val_mae: 0.3081 - val_mape: 1793213.1250 - val_msle: 0.0046\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00050: saving model to emd_loss_models/3252561351last.h5\n",
      "Epoch 51/51\n",
      "1432/1432 [==============================] - 35s 24ms/step - loss: 0.0069 - mse: 0.1832 - mae: 0.3327 - mape: 1761460.6364 - msle: 0.0046 - val_loss: 0.0055 - val_mse: 0.1191 - val_mae: 0.2601 - val_mape: 2181569.7500 - val_msle: 0.0033\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.00517\n",
      "\n",
      "Epoch 00051: saving model to emd_loss_models/3252561351last.h5\n"
     ]
    }
   ],
   "source": [
    "!python3 train_emdloss.py -i /home/rsshenoy/ecoder/data/nElinks_5/ --epoch 50 --best 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-02 08:57:36.105481: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:36.105526: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-07-02 08:57:37.951027: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 08:57:37.952054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-02 08:57:38.027768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:da:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.73GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-02 08:57:38.027908: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:38.027971: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:38.028028: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:38.028080: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:38.028136: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:38.028187: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:38.028237: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:38.028290: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 08:57:38.028304: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-02 08:57:38.028706: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-02 08:57:38.041460: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 08:57:38.041507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-02 08:57:38.041517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "[2021-07-02 08:57:38,275] INFO: Namespace(AEonly=1, double=False, epochs=10, evalOnly=False, full=False, inputFile='/home/rsshenoy/ecoder/data/nElinks_5/', loss=None, maskEnergies=False, maskPartials=False, maxVal=-1, models='8x8_c8_S2_emd1', nCSV=50, nElinks=5, noHeader=True, nrowsPerFile=500000, occReweight=False, odir='./test/', overrideInput=False, quantize=False, quickTrain=False, rescaleInputToMax=0, rescaleOutputToMax=0, retrain=False, saveEnergy=False, skipPlot=False)\n",
      "[2021-07-02 08:57:40,074] INFO: Input data shape\n",
      "(490126, 48)\n",
      "[2021-07-02 08:57:42,799] INFO: Have not found trained weights in dir: ./test/8x8_c8_S2_emd1/8x8_c8_S2_emd1.hdf5\n",
      "[2021-07-02 08:57:44,211] INFO: Model is a denseCNN\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 8, 1)]         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 4, 4, 8)           80        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "encoded_vector (Dense)       (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 2,144\n",
      "Trainable params: 2,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 1)           73        \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 8, 8, 1)           0         \n",
      "=================================================================\n",
      "Total params: 2,833\n",
      "Trainable params: 2,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 8, 1)]         0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 16)                2144      \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 8, 8, 1)           2833      \n",
      "=================================================================\n",
      "Total params: 4,977\n",
      "Trainable params: 4,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Using optimizer adam\n",
      "[2021-07-02 08:57:44,634] INFO: Training shape\n",
      "(392101, 8, 8, 1)\n",
      "[2021-07-02 08:57:44,634] INFO: Validation shape\n",
      "(98025, 8, 8, 1)\n",
      "2021-07-02 08:57:44.950568: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-07-02 08:57:44.951104: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2100000000 Hz\n",
      "Epoch 1/10\n",
      "785/785 [==============================] - 114s 145ms/step - loss: 3.8000 - val_loss: 0.6023\n",
      "Epoch 2/10\n",
      "785/785 [==============================] - 107s 137ms/step - loss: 0.5481 - val_loss: 0.5478\n",
      "Epoch 3/10\n",
      "785/785 [==============================] - 106s 135ms/step - loss: 0.5043 - val_loss: 0.5157\n",
      "Epoch 4/10\n",
      "785/785 [==============================] - 107s 136ms/step - loss: 0.4832 - val_loss: 0.4996\n",
      "Epoch 5/10\n",
      "785/785 [==============================] - 107s 136ms/step - loss: 0.4720 - val_loss: 0.4696\n",
      "Epoch 6/10\n",
      "785/785 [==============================] - 109s 139ms/step - loss: 0.4239 - val_loss: 0.4315\n",
      "Epoch 7/10\n",
      "785/785 [==============================] - 108s 138ms/step - loss: 0.4070 - val_loss: 0.4218\n",
      "Epoch 8/10\n",
      "785/785 [==============================] - 110s 140ms/step - loss: 0.4010 - val_loss: 0.4229\n",
      "Epoch 9/10\n",
      "785/785 [==============================] - 110s 140ms/step - loss: 0.3975 - val_loss: 0.4159\n",
      "Epoch 10/10\n",
      "785/785 [==============================] - 108s 138ms/step - loss: 0.3952 - val_loss: 0.4119\n",
      "2021-07-02 09:15:52.094245: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-07-02 09:15:52.094369: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-07-02 09:15:52.094989: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 09:15:52.097378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:da:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.73GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-02 09:15:52.097637: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.097715: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.097774: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.097857: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.097914: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.097970: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.098023: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.098079: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.098090: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-02 09:15:52.282780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-02 09:15:52.282881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-02 09:15:52.282903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-02 09:15:52.299307: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.006ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2021-07-02 09:15:52.372240: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-07-02 09:15:52.372342: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-07-02 09:15:52.372736: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 09:15:52.375614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:da:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.73GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-02 09:15:52.375811: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.375896: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.375960: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.376025: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.376087: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.376153: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.376215: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.376278: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.376290: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-02 09:15:52.376344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-02 09:15:52.376353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-02 09:15:52.376362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-02 09:15:52.382382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n",
      "2021-07-02 09:15:52.446827: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-07-02 09:15:52.446899: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-07-02 09:15:52.447273: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 09:15:52.449329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:da:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.73GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-02 09:15:52.449506: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.449566: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.449616: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.449694: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.449743: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.449798: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.449849: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.449899: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.449910: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-02 09:15:52.449929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-02 09:15:52.449936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-02 09:15:52.449943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-02 09:15:52.455301: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "2021-07-02 09:15:52.530677: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-07-02 09:15:52.530745: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-07-02 09:15:52.531148: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 09:15:52.533152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:da:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.73GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-02 09:15:52.533288: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.533349: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.533400: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.533450: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.533499: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.534015: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.534293: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.534497: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:15:52.534525: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-02 09:15:52.534571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-02 09:15:52.534588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-02 09:15:52.534604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-02 09:15:52.546572: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.004ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.001ms.\n",
      "\n",
      "1 encoder unique weights 72\n",
      "2 decoder unique weights 2048\n",
      "1 conv2d unique weights 72\n",
      "2 no weights\n",
      "3 encoded_vector unique weights 2048\n",
      "1 dense unique weights 2048\n",
      "2 no weights\n",
      "3 conv2d_transpose unique weights 576\n",
      "4 conv2d_transpose_1 unique weights 72\n",
      "5 no weights\n",
      "[2021-07-02 09:15:53,555] INFO: Evaluate AutoEncoder, model 8x8_c8_S2_emd1\n",
      "[2021-07-02 09:16:03,203] INFO: inputQ shape\n",
      "(98025, 8, 8, 1)\n",
      "[2021-07-02 09:16:03,204] INFO: inputcalQ shape\n",
      "(98025, 48)\n",
      "[2021-07-02 09:16:03,204] INFO: Restore normalization\n",
      "[2021-07-02 09:16:04,639] INFO: Renormalize inputs of AE for comparisons\n",
      "train.py:80: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"normalize\" failed type inference due to: \u001b[1mCan't unify return type from the following types: Tuple(array(float32, 2d, C), array(float32, 1d, C), array(float32, 1d, C)), Tuple(array(float32, 2d, C), array(float32, 1d, C), array(float64, 1d, C))\n",
      "\u001b[1mReturn of: IR name '$268return_value.10', type 'Tuple(array(float32, 2d, C), array(float32, 1d, C), array(float64, 1d, C))', location: \u001b[1m\n",
      "File \"train.py\", line 96:\u001b[0m\n",
      "\u001b[1mdef normalize(data,rescaleInputToMax=False, sumlog2=True):\n",
      "    <source elided>\n",
      "    if sumlog2:\n",
      "\u001b[1m        return  data,np.array(maxes),np.array(sums_log2)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\u001b[0m\n",
      "\u001b[1mReturn of: IR name '$290return_value.10', type 'Tuple(array(float32, 2d, C), array(float32, 1d, C), array(float32, 1d, C))', location: \u001b[1m\n",
      "File \"train.py\", line 98:\u001b[0m\n",
      "\u001b[1mdef normalize(data,rescaleInputToMax=False, sumlog2=True):\n",
      "    <source elided>\n",
      "    else:\n",
      "\u001b[1m        return data,np.array(maxes),np.array(sums)\n",
      "\u001b[0m        \u001b[1m^\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\n",
      "  @numba.jit\n",
      "train.py:80: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"normalize\" failed type inference due to: \u001b[1m\u001b[1mcannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"train.py\", line 85:\u001b[0m\n",
      "\u001b[1mdef normalize(data,rescaleInputToMax=False, sumlog2=True):\n",
      "    <source elided>\n",
      "    sums_log2=[]\n",
      "\u001b[1m    for i in range(len(data)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @numba.jit\n",
      "/opt/conda/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"normalize\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"train.py\", line 82:\u001b[0m\n",
      "\u001b[1mdef normalize(data,rescaleInputToMax=False, sumlog2=True):\n",
      "\u001b[1m    maxes =[]\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/opt/conda/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"train.py\", line 82:\u001b[0m\n",
      "\u001b[1mdef normalize(data,rescaleInputToMax=False, sumlog2=True):\n",
      "\u001b[1m    maxes =[]\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "train.py:80: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"normalize\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: typing of argument at train.py (85)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"train.py\", line 85:\u001b[0m\n",
      "\u001b[1mdef normalize(data,rescaleInputToMax=False, sumlog2=True):\n",
      "    <source elided>\n",
      "    sums_log2=[]\n",
      "\u001b[1m    for i in range(len(data)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @numba.jit\n",
      "/opt/conda/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"normalize\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"train.py\", line 85:\u001b[0m\n",
      "\u001b[1mdef normalize(data,rescaleInputToMax=False, sumlog2=True):\n",
      "    <source elided>\n",
      "    sums_log2=[]\n",
      "\u001b[1m    for i in range(len(data)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/opt/conda/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"train.py\", line 85:\u001b[0m\n",
      "\u001b[1mdef normalize(data,rescaleInputToMax=False, sumlog2=True):\n",
      "    <source elided>\n",
      "    sums_log2=[]\n",
      "\u001b[1m    for i in range(len(data)):\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "[2021-07-02 09:16:05,717] INFO: Running non-AE algorithms\n",
      "2021-07-02 09:16:06.010638: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2021-07-02 09:16:06.010740: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
      "2021-07-02 09:16:06.011556: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-07-02 09:16:06.013774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:da:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.73GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-07-02 09:16:06.014067: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:16:06.014145: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:16:06.014201: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:16:06.014253: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:16:06.014304: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:16:06.014358: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:16:06.014411: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:16:06.014465: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib64:/usr/local/cuda/lib64\n",
      "2021-07-02 09:16:06.014475: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-07-02 09:16:06.014501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-02 09:16:06.014510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2021-07-02 09:16:06.014519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2021-07-02 09:16:06.024154: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.002ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0ms.\n",
      "\n",
      "WARNING:tensorflow:From /home/rsshenoy/.local/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py:4893: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          \n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/6.54k flops)\n",
      "  encoder/encoded_vector/MatMul (4.10k/4.10k flops)\n",
      "  encoder/conv2d/Conv2D (2.30k/2.30k flops)\n",
      "  encoder/conv2d/BiasAdd (128/128 flops)\n",
      "  encoder/encoded_vector/BiasAdd (16/16 flops)\n",
      "\n",
      "======================End of Report==========================\n",
      "[2021-07-02 09:16:44,784] INFO: Summary_dict\n",
      "{'name': '8x8_c8_S2_emd1', 'en_pams': 2144, 'en_flops': 6544, 'tot_pams': 4977, 'EMD_ae': 3.26, 'EMD_ae_err': 1.441}\n",
      "             name en_pams tot_pams  ... EMD_thr_hi_err  EMD_bc  EMD_bc_err\n",
      "0  8x8_c8_S2_emd1    2144     4977  ...            NaN     NaN         NaN\n",
      "\n",
      "[1 rows x 14 columns]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 train.py -i /home/rsshenoy/ecoder/data/nElinks_5/  -o ./test/ --epoch 10 --AEonly 1 --nELinks 5 --noHeader --models 8x8_c8_S2_emd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

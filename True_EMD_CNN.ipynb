{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c841e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 16:54:24.453687: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mplhep as hep\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.wafer import plot_wafer as plotWafer\n",
    "\n",
    "from utils.metrics import emd\n",
    "from utils.metrics import hexMetric\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, BatchNormalization, Activation, Average, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "        \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "current_directory=os.getcwd()\n",
    "\n",
    "def load_data(inputFile):\n",
    "    noHeader=True\n",
    "\n",
    "    # charge data headers of 48 Input Trigger Cells (TC) \n",
    "    CALQ_COLS = ['CALQ_%i'%c for c in range(0, 48)]\n",
    "\n",
    "    if os.path.isdir(inputFile):\n",
    "        df_arr = []\n",
    "        for infile in os.listdir(inputFile):\n",
    "            if os.path.isdir(inputFile+infile): continue\n",
    "            infile = os.path.join(inputFile,infile)\n",
    "            df_arr.append(pd.read_csv(infile, dtype=np.float64, header=0, usecols=[*range(0, 48)], names=CALQ_COLS))\n",
    "        data = pd.concat(df_arr)\n",
    "    else:\n",
    "        data = pd.read_csv(inputFile)\n",
    "        \n",
    "    data = data.astype('float64')\n",
    "    \n",
    "    data_values = data.values\n",
    "   \n",
    "    return data_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bcf5efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98024, 48)\n",
      "(98024, 48)\n"
     ]
    }
   ],
   "source": [
    "#Take dataset from previous Autoencoder Training\n",
    "csv_directory=os.path.join(current_directory,'test1','8x8_c8_S2_tele')\n",
    "input_loc=os.path.join(csv_directory,'verify_input_calQ.csv')\n",
    "\n",
    "q_input_data=load_data(input_loc)\n",
    "\n",
    "print(q_input_data.shape)\n",
    "\n",
    "remap_8x8 = [4, 12, 20, 28,  5, 13, 21, 29,  6, 14, 22, 30,  7, 15, 23, 31, \n",
    "             24, 25, 26, 27, 16, 17, 18, 19,  8,  9, 10, 11,  0,  1,  2,  3, \n",
    "             59, 51, 43, 35, 58, 50, 42, 34, 57, 49, 41, 33, 56, 48, 40, 32]\n",
    "\n",
    "output_loc=os.path.join(csv_directory,'verify_decoded_calQ.csv')\n",
    "ae_input_data=load_data(output_loc)\n",
    "print(ae_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117acfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get True EMD Values\n",
    "indices = range(0, len(q_input_data))\n",
    "emd_values = np.array([emd(q_input_data[i],ae_input_data[j]) for i, j in zip(indices,indices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2ed595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot True EMD for input vs AE(input)\n",
    "\n",
    "fig=plt.figure()\n",
    "fig=plt.hist(emd_values, alpha=1, bins=np.arange(0, 2.5,0.01), label='TrueEMD')\n",
    "fig=plt.xlabel('EMD [GeV]')\n",
    "fig=plt.ylabel('Samples')\n",
    "fig=plt.legend()\n",
    "plt.savefig(os.path.join(current_directory,'TrueEMD.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcb608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 16:55:09.657537: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-28 16:55:09.755572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:3e:00.0 name: TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-07-28 16:55:09.755631: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-28 16:55:09.775580: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-28 16:55:09.775671: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-28 16:55:09.776880: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-28 16:55:09.788951: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-28 16:55:09.795235: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-28 16:55:09.800199: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-28 16:55:09.800403: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-28 16:55:09.802786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-28 16:55:09.838661: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-28 16:55:09.847105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:3e:00.0 name: TITAN Xp computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\n",
      "2021-07-28 16:55:09.853495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-28 16:55:09.853560: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-28 16:55:11.563971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-28 16:55:11.564008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-28 16:55:11.564017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-28 16:55:11.566837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11426 MB memory) -> physical GPU (device: 0, name: TITAN Xp, pci bus id: 0000:3e:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shapes\n",
      "(98024, 4, 4, 3)\n",
      "(98024, 4, 4, 3)\n",
      "(58814, 4, 4, 3)\n",
      "(58814, 4, 4, 3)\n",
      "(58814,)\n",
      "(39210, 4, 4, 3)\n",
      "(39210, 4, 4, 3)\n",
      "(39210,)\n"
     ]
    }
   ],
   "source": [
    "#Arranging the hexagon\n",
    "arrange443 = np.array([0,16,32,\n",
    "                        1,17,33,\n",
    "                        2,18,34,\n",
    "                        3,19,35,\n",
    "                        4,20,36,\n",
    "                        5,21,37,\n",
    "                        6,22,38,\n",
    "                        7,23,39,\n",
    "                        8,24,40,\n",
    "                        9,25,41,\n",
    "                        10,26,42,\n",
    "                        11,27,43,\n",
    "                        12,28,44,\n",
    "                        13,29,45,\n",
    "                        14,30,46,\n",
    "                        15,31,47])\n",
    "        \n",
    "calQ     = q_input_data\n",
    "sumQ     = calQ.sum(axis=1)\n",
    "calQ     = calQ[sumQ>0]\n",
    "sumQ     = sumQ[sumQ>0]\n",
    "    \n",
    "calQ_443 = (calQ/np.expand_dims(sumQ,-1))[:,arrange443].reshape(-1,4,4,3)\n",
    "\n",
    "calA     = ae_input_data\n",
    "sumA     = tf.math.reduce_sum(calA, axis=1)\n",
    "calA     = calA[sumA>0]\n",
    "sumA     = sumA[sumA>0]\n",
    "    \n",
    "calA_443 = (calA/tf.expand_dims(sumA,-1))\n",
    "r = tf.gather(calA_443, arrange443, axis=1)\n",
    "r = tf.reshape(r, (-1, 4, 4, 3))\n",
    "calA_443=r\n",
    "\n",
    "print(\"Data Shapes\")\n",
    "print(calQ_443.shape)\n",
    "print(calA_443.shape)\n",
    "\n",
    "\n",
    "train_indices = range(0, int(0.6*len(calQ)))\n",
    "val_indices = range(int(0.6*len(calQ)), len(calQ))\n",
    "\n",
    "train_index=int(0.6*len(calQ))\n",
    "\n",
    "idx1_train = np.array([i for i in train_indices])\n",
    "idx2_train = np.array([j for j in train_indices])\n",
    "              \n",
    "X1 = calQ_443\n",
    "X2 = calA_443\n",
    "                 \n",
    "X1_train = X1[0:train_index]\n",
    "X2_train = X2[0:train_index]\n",
    "\n",
    "y_train = np.array([emd(calQ[i],calA[j]) for i, j in zip(train_indices,train_indices)])\n",
    "\n",
    "X1_val = X1[train_index:]\n",
    "X2_val = X2[train_index:]\n",
    "y_val = np.array([emd(calQ[i],calA[j]) for i, j in zip(val_indices, val_indices)])\n",
    "    \n",
    "print(X1_train.shape)\n",
    "print(X2_train.shape)\n",
    "print(y_train.shape)\n",
    "    \n",
    "print(X1_val.shape)\n",
    "print(X2_val.shape)\n",
    "print(y_val.shape)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50b22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"base_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 4, 4, 6)      0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 4, 32)     4832        concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_1 (BatchNormalization (None, 4, 4, 32)     128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_1 (Activation)             (None, 4, 4, 32)     0           batchnorm_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 32)     25632       relu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_2 (BatchNormalization (None, 4, 4, 32)     128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_2 (Activation)             (None, 4, 4, 32)     0           batchnorm_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 4, 4, 32)     25632       relu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm_3 (BatchNormalization (None, 4, 4, 32)     128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_3 (Activation)             (None, 4, 4, 32)     0           batchnorm_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           relu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batchnorm4 (BatchNormalization) (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_4 (Activation)             (None, 256)          0           batchnorm4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            257         relu_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 189,089\n",
      "Trainable params: 188,385\n",
      "Non-trainable params: 704\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 16:55:51.667917: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-28 16:55:51.680354: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3000000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-28 16:55:53.255711: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-28 16:55:54.364957: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8101\n",
      "2021-07-28 16:55:55.876248: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-28 16:55:56.887398: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1838/1838 [==============================] - 18s 7ms/step - loss: 0.0652 - mse: 0.0730 - mae: 0.1867 - mape: 17.4190 - msle: 0.0141 - val_loss: 0.0379 - val_mse: 0.0346 - val_mae: 0.1518 - val_mape: 13.9071 - val_msle: 0.0081\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03792, saving model to emd_loss_models/3252561340best.h5\n",
      "\n",
      "Epoch 00001: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 2/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0282 - mse: 0.0281 - mae: 0.1292 - mape: 12.1743 - msle: 0.0059 - val_loss: 0.0148 - val_mse: 0.0109 - val_mae: 0.0797 - val_mape: 7.6257 - val_msle: 0.0025\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03792 to 0.01476, saving model to emd_loss_models/3252561340best.h5\n",
      "\n",
      "Epoch 00002: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 3/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0184 - mse: 0.0231 - mae: 0.1176 - mape: 11.1331 - msle: 0.0049 - val_loss: 0.0152 - val_mse: 0.0200 - val_mae: 0.1202 - val_mape: 11.6342 - val_msle: 0.0050\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01476\n",
      "\n",
      "Epoch 00003: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 4/40\n",
      "1838/1838 [==============================] - 12s 7ms/step - loss: 0.0147 - mse: 0.0203 - mae: 0.1097 - mape: 10.3546 - msle: 0.0043 - val_loss: 0.0091 - val_mse: 0.0103 - val_mae: 0.0798 - val_mape: 7.5802 - val_msle: 0.0024\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01476 to 0.00915, saving model to emd_loss_models/3252561340best.h5\n",
      "\n",
      "Epoch 00004: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 5/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0126 - mse: 0.0175 - mae: 0.1025 - mape: 9.7109 - msle: 0.0038 - val_loss: 0.0558 - val_mse: 0.1040 - val_mae: 0.2970 - val_mape: 30.0331 - val_msle: 0.0320\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00915\n",
      "\n",
      "Epoch 00005: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 6/40\n",
      "1838/1838 [==============================] - 12s 7ms/step - loss: 0.0116 - mse: 0.0161 - mae: 0.0987 - mape: 9.3697 - msle: 0.0035 - val_loss: 0.0572 - val_mse: 0.1076 - val_mae: 0.3020 - val_mape: 29.4789 - val_msle: 0.0307\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00915\n",
      "\n",
      "Epoch 00006: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 7/40\n",
      "1838/1838 [==============================] - 12s 7ms/step - loss: 0.0115 - mse: 0.0160 - mae: 0.0981 - mape: 9.3127 - msle: 0.0035 - val_loss: 0.0150 - val_mse: 0.0234 - val_mae: 0.1330 - val_mape: 12.7640 - val_msle: 0.0059\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00915\n",
      "\n",
      "Epoch 00007: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 8/40\n",
      "1838/1838 [==============================] - 16s 9ms/step - loss: 0.0104 - mse: 0.0144 - mae: 0.0932 - mape: 8.8646 - msle: 0.0031 - val_loss: 0.0345 - val_mse: 0.0630 - val_mae: 0.2302 - val_mape: 22.9337 - val_msle: 0.0164\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00915\n",
      "\n",
      "Epoch 00008: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 9/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0100 - mse: 0.0141 - mae: 0.0920 - mape: 8.7442 - msle: 0.0030 - val_loss: 0.0434 - val_mse: 0.0809 - val_mae: 0.2485 - val_mape: 25.8429 - val_msle: 0.0263\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00915\n",
      "\n",
      "Epoch 00009: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 10/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0095 - mse: 0.0134 - mae: 0.0900 - mape: 8.5692 - msle: 0.0029 - val_loss: 0.0280 - val_mse: 0.0506 - val_mae: 0.1979 - val_mape: 21.1180 - val_msle: 0.0120\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00915\n",
      "\n",
      "Epoch 00010: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 11/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0090 - mse: 0.0129 - mae: 0.0881 - mape: 8.3698 - msle: 0.0028 - val_loss: 0.0207 - val_mse: 0.0365 - val_mae: 0.1639 - val_mape: 17.8168 - val_msle: 0.0090\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00915\n",
      "\n",
      "Epoch 00011: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 12/40\n",
      "1838/1838 [==============================] - 12s 7ms/step - loss: 0.0086 - mse: 0.0123 - mae: 0.0859 - mape: 8.1734 - msle: 0.0027 - val_loss: 0.0074 - val_mse: 0.0101 - val_mae: 0.0825 - val_mape: 8.0539 - val_msle: 0.0025\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00915 to 0.00744, saving model to emd_loss_models/3252561340best.h5\n",
      "\n",
      "Epoch 00012: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 13/40\n",
      "1838/1838 [==============================] - 14s 8ms/step - loss: 0.0086 - mse: 0.0125 - mae: 0.0866 - mape: 8.2190 - msle: 0.0027 - val_loss: 0.0231 - val_mse: 0.0417 - val_mae: 0.1804 - val_mape: 18.5598 - val_msle: 0.0124\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00744\n",
      "\n",
      "Epoch 00013: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 14/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0083 - mse: 0.0121 - mae: 0.0855 - mape: 8.1198 - msle: 0.0026 - val_loss: 0.0235 - val_mse: 0.0424 - val_mae: 0.1775 - val_mape: 19.3885 - val_msle: 0.0104\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00744\n",
      "\n",
      "Epoch 00014: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 15/40\n",
      "1838/1838 [==============================] - 12s 7ms/step - loss: 0.0078 - mse: 0.0113 - mae: 0.0827 - mape: 7.8594 - msle: 0.0024 - val_loss: 0.0136 - val_mse: 0.0229 - val_mae: 0.1317 - val_mape: 13.3178 - val_msle: 0.0063\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00744\n",
      "\n",
      "Epoch 00015: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 16/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0080 - mse: 0.0116 - mae: 0.0839 - mape: 7.9647 - msle: 0.0025 - val_loss: 0.0113 - val_mse: 0.0182 - val_mae: 0.1161 - val_mape: 11.2878 - val_msle: 0.0046\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00744\n",
      "\n",
      "Epoch 00016: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 17/40\n",
      "1838/1838 [==============================] - 14s 8ms/step - loss: 0.0077 - mse: 0.0112 - mae: 0.0822 - mape: 7.8281 - msle: 0.0024 - val_loss: 0.0091 - val_mse: 0.0141 - val_mae: 0.0986 - val_mape: 10.3264 - val_msle: 0.0034\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00744\n",
      "\n",
      "Epoch 00017: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 18/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0077 - mse: 0.0113 - mae: 0.0823 - mape: 7.7972 - msle: 0.0024 - val_loss: 0.0061 - val_mse: 0.0081 - val_mae: 0.0709 - val_mape: 6.6548 - val_msle: 0.0018\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00744 to 0.00609, saving model to emd_loss_models/3252561340best.h5\n",
      "\n",
      "Epoch 00018: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 19/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0075 - mse: 0.0110 - mae: 0.0814 - mape: 7.7478 - msle: 0.0024 - val_loss: 0.0055 - val_mse: 0.0070 - val_mae: 0.0659 - val_mape: 6.5252 - val_msle: 0.0016\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00609 to 0.00550, saving model to emd_loss_models/3252561340best.h5\n",
      "\n",
      "Epoch 00019: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 20/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0074 - mse: 0.0108 - mae: 0.0808 - mape: 7.6758 - msle: 0.0023 - val_loss: 0.0067 - val_mse: 0.0095 - val_mae: 0.0782 - val_mape: 7.7266 - val_msle: 0.0023\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00550\n",
      "\n",
      "Epoch 00020: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 21/40\n",
      "1838/1838 [==============================] - 13s 7ms/step - loss: 0.0072 - mse: 0.0106 - mae: 0.0799 - mape: 7.5736 - msle: 0.0023 - val_loss: 0.0068 - val_mse: 0.0097 - val_mae: 0.0788 - val_mape: 7.3403 - val_msle: 0.0022\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00550\n",
      "\n",
      "Epoch 00021: saving model to emd_loss_models/3252561340last.h5\n",
      "Epoch 22/40\n",
      "1360/1838 [=====================>........] - ETA: 3s - loss: 0.0072 - mse: 0.0105 - mae: 0.0795 - mape: 7.5665 - msle: 0.0023"
     ]
    }
   ],
   "source": [
    "#EMD CNN Hyperparamters\n",
    "num_filt=32\n",
    "kernel_size=5\n",
    "num_dens_neurons=256\n",
    "num_dens_layers=1\n",
    "num_conv_2d=3\n",
    "\n",
    "num_epochs=40\n",
    "\n",
    "current_directory=os.getcwd()\n",
    "\n",
    "#Building CNN\n",
    "        \n",
    "# make a convolutional model as a more advanced PoC\n",
    "input1 = Input(shape=(4, 4, 3,), name='input_1')\n",
    "input2 = Input(shape=(4, 4, 3,), name='input_2')\n",
    "x = Concatenate(name='concat')([input1, input2])\n",
    "            \n",
    "#Number of Conv2D Layers\n",
    "for i in range(1,num_conv_2d+1):\n",
    "    ind=str(i)\n",
    "    x = Conv2D(num_filt, kernel_size, strides=(1, 1), name='conv2d_'+ind, padding='same', kernel_regularizer=l1_l2(l1=0,l2=1e-4))(x)\n",
    "    x = BatchNormalization(name='batchnorm_'+ind)(x)\n",
    "    x = Activation('relu', name='relu_'+ind)(x)\n",
    "                \n",
    "x = Flatten(name='flatten')(x)\n",
    "            \n",
    "#Number of Dense Layers\n",
    "for i in range(1,num_dens_layers+1):\n",
    "    ind=str(i)\n",
    "    jind=str(i+num_conv_2d)\n",
    "    x = Dense(num_dens_neurons, name='dense_'+ind, kernel_regularizer=l1_l2(l1=0,l2=1e-4))(x)\n",
    "    x = BatchNormalization(name='batchnorm'+jind)(x)\n",
    "    x = Activation('relu', name='relu_'+jind)(x)\n",
    "                \n",
    "output = Dense(1, name='output')(x)\n",
    "model = Model(inputs=[input1, input2], outputs=output, name='base_model')\n",
    "model.summary()\n",
    "                \n",
    "final_directory=os.path.join(current_directory,r'emd_loss_models')\n",
    "if not os.path.exists(final_directory):\n",
    "        os.makedirs(final_directory)\n",
    "callbacks = [ModelCheckpoint('emd_loss_models/'+str(num_filt)+str(kernel_size)+str(num_dens_neurons)+str(num_dens_layers)+str(num_conv_2d)+str(num_epochs)+'best.h5', monitor='val_loss', verbose=1, save_best_only=True),\n",
    "                ModelCheckpoint('emd_loss_models/'+str(num_filt)+str(kernel_size)+str(num_dens_neurons)+str(num_dens_layers)+str(num_conv_2d)+str(num_epochs)+'last.h5', monitor='val_loss', verbose=1, save_last_only=True),\n",
    "            ]\n",
    "            \n",
    "model.compile(optimizer='adam', loss='huber_loss', metrics=['mse', 'mae', 'mape', 'msle'])\n",
    "history = model.fit((X1_train, X2_train), y_train, \n",
    "                    validation_data=((X1_val, X2_val), y_val),\n",
    "                    epochs=num_epochs, verbose=1, batch_size=32, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7caaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making directory for graphs\n",
    "        \n",
    "img_directory=os.path.join(current_directory,r'Performance on Predicting True EMD')\n",
    "if not os.path.exists(img_directory):\n",
    "    os.makedirs(img_directory)\n",
    "        \n",
    "#Plot Validation loss and training loss\n",
    "        \n",
    "plt.close()\n",
    "fig=plt.plot(history.history['loss'], label='Train')\n",
    "fig=plt.plot(history.history['val_loss'], label='Val.')\n",
    "fig=plt.xlabel('Epoch')\n",
    "fig=plt.ylabel('MSLE loss')\n",
    "fig=plt.legend()\n",
    "plt.savefig(img_directory+\"/\"+str(num_filt)+str(kernel_size)+str(num_dens_neurons)+str(num_dens_layers)+str(num_conv_2d)+str(num_epochs)+\"Loss.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "        \n",
    "#Plots True EMD and Pred Emd Histogram\n",
    "        \n",
    "plt.close()\n",
    "y_val_preds = model.predict((X1_val, X2_val))\n",
    "fig=plt.figure()\n",
    "fig=plt.hist(y_val, alpha=0.5, bins=np.arange(0, 2.5,0.01), label='TrueEMD')\n",
    "fig=plt.hist(y_val_preds, alpha=0.5, bins=np.arange(0, 2.5,0.01), label='EMDCNN')\n",
    "fig=plt.xlabel('EMD [GeV]')\n",
    "fig=plt.ylabel('Samples')\n",
    "fig=plt.legend()\n",
    "fig=plt.savefig(img_directory+\"/\"+str(num_filt)+str(kernel_size)+str(num_dens_neurons)+str(num_dens_layers)+str(num_conv_2d)+str(num_epochs)+\"Hist.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "        \n",
    "#Plot Relative Difference\n",
    "        \n",
    "plt.close()\n",
    "rel_diff = (y_val_preds[y_val>0].flatten()-y_val[y_val>0].flatten())/y_val[y_val>0].flatten()\n",
    "fig=plt.figure()\n",
    "fig=plt.hist(rel_diff, bins=np.arange(-1, 1, 0.01), color='green', label = 'mean = {:.3f}, std. = {:.3f}'.format(np.mean(rel_diff), np.std(rel_diff)))\n",
    "fig=plt.xlabel('EMD rel. diff.')\n",
    "fig=plt.ylabel('Samples')\n",
    "fig=plt.legend()\n",
    "fig=plt.savefig(img_directory+\"/\"+str(num_filt)+str(kernel_size)+str(num_dens_neurons)+str(num_dens_layers)+str(num_conv_2d)+str(num_epochs)+\"RelD.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "        \n",
    "#Plot True EMD vs Pred Emd Graphic\n",
    "        \n",
    "plt.close()\n",
    "fig, ax = plt.subplots(figsize =(5, 5)) \n",
    "x_bins = np.arange(0, 4, 0.1)\n",
    "y_bins = np.arange(0, 4, 0.1)\n",
    "plt.hist2d(y_val.flatten(), y_val_preds.flatten(), bins=[x_bins,y_bins])\n",
    "plt.plot([0, 15], [0, 15], color='gray', alpha=0.5)\n",
    "ax.set_xlabel('True EMD [GeV]')\n",
    "ax.set_ylabel('Pred. EMD [GeV]')\n",
    "fig=plt.savefig(img_directory+\"/\"+str(num_filt)+str(kernel_size)+str(num_dens_neurons)+str(num_dens_layers)+str(num_conv_2d)+str(num_epochs)+\"Graphic.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e3bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

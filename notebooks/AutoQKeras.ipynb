{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import pprint\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense\n",
    "from qkeras import quantizers\n",
    "from qkeras.qtools import run_qtools\n",
    "from qkeras.qtools import settings as qtools_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa12949a670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa12949a670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa12949a670>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method QConv2D.call of <qkeras.qconvolutional.QConv2D object at 0x7fa12949a0a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method QConv2D.call of <qkeras.qconvolutional.QConv2D object at 0x7fa12949a0a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method QConv2D.call of <qkeras.qconvolutional.QConv2D object at 0x7fa12949a0a0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa12979fc10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa12979fc10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa12979fc10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method QDense.call of <qkeras.qlayers.QDense object at 0x7fa128ddecd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method QDense.call of <qkeras.qlayers.QDense object at 0x7fa128ddecd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method QDense.call of <qkeras.qlayers.QDense object at 0x7fa128ddecd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa128fe4cd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa128fe4cd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method QActivation.call of <qkeras.qlayers.QActivation object at 0x7fa128fe4cd0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "from graphUtil import *\n",
    "\n",
    "m = '../V11/signal/nElinks_5/Nov10_8x8_c8_S2_qK_RTL/encoder_Nov10_8x8_c8_S2_qK_RTL.json'\n",
    "weights_path = '../V11/signal/nElinks_5/Nov10_8x8_c8_S2_qK_RTL/encoder_Nov10_8x8_c8_S2_qK_RTL.hdf5'\n",
    "\n",
    "encoder = loadModel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 8, 1)]         0         \n",
      "_________________________________________________________________\n",
      "input_qa (QActivation)       (None, 8, 8, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_0_m (QConv2D)         (None, 4, 4, 8)           80        \n",
      "_________________________________________________________________\n",
      "accum1_qa (QActivation)      (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "encoded_vector (QDense)      (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "encod_qa (QActivation)       (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 2,144\n",
      "Trainable params: 2,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_profile(reference_internal,reference_accumulator):\n",
    "#     reference_internal = \"fp32\"\n",
    "    #     reference_accumulator = \"fp32\"\n",
    "\n",
    "    q = run_qtools.QTools(\n",
    "      encoder,\n",
    "      # energy calculation using a given process\n",
    "      process=\"horowitz\",\n",
    "      # quantizers for model input\n",
    "      source_quantizers=[quantizers.quantized_bits(8, 0, 1)],\n",
    "      is_inference=False,\n",
    "      # absolute path (including filename) of the model weights\n",
    "      weights_path=weights_path,\n",
    "      # keras_quantizer to quantize weight/bias in un-quantized keras layers\n",
    "      keras_quantizer=reference_internal,\n",
    "      # keras_quantizer to quantize MAC in un-quantized keras layers\n",
    "      keras_accumulator=reference_accumulator,\n",
    "      # whether calculate baseline energy\n",
    "      for_reference=True)\n",
    "\n",
    "    q.qtools_stats_print()\n",
    "\n",
    "    # dump the layer data map to a json file\n",
    "    # json_name = \"qtool_stat.json\"\n",
    "    # q.qtools_stats_to_json(json_name)\n",
    "\n",
    "    # caculate energy of the derived data type map.\n",
    "    ref_energy_dict = q.pe(\n",
    "      # whether to store parameters in dram, sram, or fixed\n",
    "      weights_on_memory=\"sram\",\n",
    "      # store activations in dram or sram\n",
    "      activations_on_memory=\"sram\",\n",
    "      # minimum sram size in number of bits\n",
    "      min_sram_size=8*16*1024*1024,\n",
    "      # whether load data from dram to sram (consider sram as a cache\n",
    "      # for dram. If false, we will assume data will be already in SRAM\n",
    "      rd_wr_on_io=False)\n",
    "\n",
    "\n",
    "    # get stats of energy distribution in each layer\n",
    "    reference_energy_profile = q.extract_energy_profile(\n",
    "                                      qtools_settings.cfg.include_energy,\n",
    "                                      ref_energy_dict)\n",
    "    # reference_energy_profile_fp32 = qfp32.extract_energy_profile(\n",
    "    #                                   qtools_settings.cfg.include_energy,\n",
    "    #                                   ref_energy_dict)\n",
    "\n",
    "    # extract sum of energy of each layer according to the rule specified in\n",
    "    # qtools_settings.cfg.include_energy\n",
    "    # total_reference_energy = q.extract_energy_sum(\n",
    "    #                           qtools_settings.cfg.include_energy,\n",
    "    #                         ref_energy_dict)\n",
    "    # pprint.pprint(reference_energy_profile)\n",
    "    # print(\"Total baseline energy:\", total_reference_energy)\n",
    "    \n",
    "    return reference_energy_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"source_quantizers\": [\n",
      "        {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 0,\n",
      "            \"is_signed\": true\n",
      "        }\n",
      "    ],\n",
      "    \"input_qa\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 0,\n",
      "                \"is_signed\": true\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                8,\n",
      "                8,\n",
      "                1\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 64\n",
      "    },\n",
      "    \"conv2d_0_m\": {\n",
      "        \"layer_type\": \"QConv2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                3,\n",
      "                1,\n",
      "                8\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": 8\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                4,\n",
      "                4,\n",
      "                8\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1152\n",
      "    },\n",
      "    \"accum1_qa\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                4,\n",
      "                4,\n",
      "                8\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 128\n",
      "    },\n",
      "    \"flatten\": {\n",
      "        \"layer_type\": \"Flatten\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 128\n",
      "    },\n",
      "    \"encoded_vector\": {\n",
      "        \"layer_type\": \"QDense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                128,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": 16\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 2048\n",
      "    },\n",
      "    \"encod_qa\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 16\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 16,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 16\n",
      "    }\n",
      "}\n",
      "{\n",
      "    \"source_quantizers\": [\n",
      "        {\n",
      "            \"quantizer_type\": \"quantized_bits\",\n",
      "            \"bits\": 8,\n",
      "            \"int_bits\": 0,\n",
      "            \"is_signed\": true\n",
      "        }\n",
      "    ],\n",
      "    \"input_qa\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"quantized_bits\",\n",
      "                \"bits\": 8,\n",
      "                \"int_bits\": 0,\n",
      "                \"is_signed\": true\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                8,\n",
      "                8,\n",
      "                1\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 64\n",
      "    },\n",
      "    \"conv2d_0_m\": {\n",
      "        \"layer_type\": \"QConv2D\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                3,\n",
      "                3,\n",
      "                1,\n",
      "                8\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 8\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                4,\n",
      "                4,\n",
      "                8\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 1152\n",
      "    },\n",
      "    \"accum1_qa\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                4,\n",
      "                4,\n",
      "                8\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 128\n",
      "    },\n",
      "    \"flatten\": {\n",
      "        \"layer_type\": \"Flatten\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                128\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 128\n",
      "    },\n",
      "    \"encoded_vector\": {\n",
      "        \"layer_type\": \"QDense\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"weight_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                128,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"bias_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": 16\n",
      "        },\n",
      "        \"multiplier\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"mul\"\n",
      "        },\n",
      "        \"accumulator\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"op_type\": \"add\"\n",
      "        },\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 2048\n",
      "    },\n",
      "    \"encod_qa\": {\n",
      "        \"layer_type\": \"QActivation\",\n",
      "        \"input_quantizer_list\": [\n",
      "            {\n",
      "                \"quantizer_type\": \"floating_point\",\n",
      "                \"bits\": 32\n",
      "            }\n",
      "        ],\n",
      "        \"output_quantizer\": {\n",
      "            \"quantizer_type\": \"floating_point\",\n",
      "            \"bits\": 32,\n",
      "            \"shape\": [\n",
      "                -1,\n",
      "                16\n",
      "            ]\n",
      "        },\n",
      "        \"operation_count\": 16\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "reference_energy_profile_fp16 = get_reference_profile('fp16','fp16')\n",
    "reference_energy_profile_fp32 = get_reference_profile('fp32','fp32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy profile:\n",
      "{'accum1_qa': {'energy': {'inputs': 136.94,\n",
      "                          'op_cost': 0.0,\n",
      "                          'outputs': 60.86,\n",
      "                          'parameters': 0.0},\n",
      "               'total': 60.86},\n",
      " 'conv2d_0_m': {'energy': {'inputs': 30.43,\n",
      "                           'op_cost': 238.71,\n",
      "                           'outputs': 136.94,\n",
      "                           'parameters': 30.43},\n",
      "                'total': 299.57},\n",
      " 'encod_qa': {'energy': {'inputs': 22.82,\n",
      "                         'op_cost': 0.0,\n",
      "                         'outputs': 11.41,\n",
      "                         'parameters': 0.0},\n",
      "              'total': 11.41},\n",
      " 'encoded_vector': {'energy': {'inputs': 60.86,\n",
      "                               'op_cost': 449.98,\n",
      "                               'outputs': 22.82,\n",
      "                               'parameters': 737.94},\n",
      "                    'total': 1248.7800000000002},\n",
      " 'flatten': {'energy': {'inputs': 60.86,\n",
      "                        'op_cost': 0.0,\n",
      "                        'outputs': 60.86,\n",
      "                        'parameters': 0.0},\n",
      "             'total': 60.86},\n",
      " 'input_qa': {'energy': {'inputs': 30.43,\n",
      "                         'op_cost': 0.0,\n",
      "                         'outputs': 30.43,\n",
      "                         'parameters': 0.0},\n",
      "              'total': 30.43}}\n",
      "Total energy: 1711\n"
     ]
    }
   ],
   "source": [
    "# By setting for_reference=False, we quantize the model using quantizers\n",
    "# specified by users in qkeras layers. For hybrid models where there are\n",
    "# mixture of unquantized keras layers and quantized qkeras layers, we use\n",
    "# keras_quantizer to quantize weights/bias and keras_accumulator to quantize\n",
    "# MAC variables for all keras layers.\n",
    "q = run_qtools.QTools(\n",
    "                      encoder,\n",
    "                      process=\"horowitz\",\n",
    "                      source_quantizers=[quantizers.quantized_bits(8, 0, 1)],\n",
    "                      is_inference=False,\n",
    "                      weights_path=weights_path,\n",
    "                      keras_quantizer=reference_internal,\n",
    "                      keras_accumulator=reference_accumulator,\n",
    "                      for_reference=False)\n",
    "trial_energy_dict = q.pe(\n",
    "                      weights_on_memory=\"sram\",\n",
    "                      activations_on_memory=\"sram\",\n",
    "                      min_sram_size=8*16*1024*1024,\n",
    "                      rd_wr_on_io=False)\n",
    "trial_energy_profile = q.extract_energy_profile(\n",
    "                        qtools_settings.cfg.include_energy,\n",
    "                        trial_energy_dict)\n",
    "total_trial_energy = q.extract_energy_sum(\n",
    "                          qtools_settings.cfg.include_energy,\n",
    "                        trial_energy_dict)\n",
    "print(\"energy profile:\")\n",
    "pprint.pprint(trial_energy_profile)\n",
    "print(\"Total energy:\", total_trial_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_energy_profile(eps,labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.arange(len(eps[0].keys()))  # the label locations\n",
    "    width = (1/len(eps)) *0.7\n",
    "    \n",
    "    def autolabel(rects):\n",
    "        \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('%i'%(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    for i,ep in enumerate(eps):\n",
    "        layers = ep.keys()    \n",
    "        data   = np.array([ep[l]['total'] for l in layers])\n",
    "        TotalEnergy = data.sum()\n",
    "        rect = ax.bar(x + i*width ,data,\n",
    "               label=labels.pop(0)+\": %i $\\mathrm{pJ}$\"%TotalEnergy,\n",
    "               width = width)  \n",
    "        #autolabel(rect)\n",
    "    ax.set_xticks(x+width*(len(eps)-1)/2)\n",
    "    ax.set_xticklabels(layers)\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_ylabel('Energy(pJ)')\n",
    "    ax.set_yscale('log')\n",
    "    fig.autofmt_xdate() \n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_energy_profile([trial_energy_profile,\n",
    "                    reference_energy_profile_fp16,\n",
    "                    reference_energy_profile_fp32],labels=['quantized','fp16','fp32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from dense2DkernelCNN import dense2DkernelCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Conv2DTranspose, Reshape, Activation, DepthwiseConv2D,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import numpy as np\n",
    "import json\n",
    "from telescope import telescopeMSE2\n",
    "\n",
    "class denseSepConv2D:\n",
    "    def __init__(self,name='',weights_f=''):\n",
    "        self.name=name\n",
    "        self.pams ={\n",
    "            'CNN_layer_nodes'  : [8],  #n_filters\n",
    "            'CNN_kernel_size'  : [3],\n",
    "            'CNN_pool'         : [False],\n",
    "            'Dense_layer_nodes': [], #does not include encoded layer\n",
    "            'encoded_dim'      : 16,\n",
    "            'shape'            : (4,4,3),\n",
    "            'channels_first'   : False,\n",
    "            'arrange'          : [],\n",
    "            'arrMask'          : [],\n",
    "            'n_copy'           : 0,      # no. of copy for hi occ datasets\n",
    "            'loss'             : ''\n",
    "        }\n",
    "\n",
    "        self.weights_f =weights_f\n",
    "        \n",
    "\n",
    "    def setpams(self,in_pams):\n",
    "        for k,v in in_pams.items():\n",
    "            self.pams[k] = v\n",
    "\n",
    "    def shuffle(self,arr):\n",
    "        order = np.arange(48)\n",
    "        np.random.shuffle(order)\n",
    "        return arr[:,order]\n",
    "            \n",
    "    def prepInput(self,normData):\n",
    "        shape = self.pams['shape']\n",
    "\n",
    "        if len(self.pams['arrange'])>0:\n",
    "          arrange = self.pams['arrange']\n",
    "          inputdata = normData[:,arrange]\n",
    "        else:\n",
    "          inputdata = normData\n",
    "        if len(self.pams['arrMask'])>0:\n",
    "          arrMask = self.pams['arrMask']\n",
    "          inputdata[:,arrMask==0]=0  #zeros out repeated entries\n",
    "\n",
    "        shaped_data = inputdata.reshape(len(inputdata),shape[0],shape[1],shape[2])\n",
    "\n",
    "        if self.pams['n_copy']>0:\n",
    "            n_copy  = self.pams['n_copy']\n",
    "            occ_low = self.pams['occ_low']\n",
    "            occ_hi = self.pams['occ_hi']\n",
    "        shaped_data = self.cloneInput(shaped_data,n_copy,occ_low,occ_hi)\n",
    "\n",
    "        return shaped_data\n",
    "\n",
    "    def weightedMSE(self, y_true, y_pred):\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        loss   = K.mean(K.square(y_true - y_pred)*K.maximum(y_pred,y_true),axis=(-1))\n",
    "        return loss\n",
    "            \n",
    "    def init(self,printSummary=True):\n",
    "        encoded_dim = self.pams['encoded_dim']\n",
    "\n",
    "        CNN_layer_nodes   = self.pams['CNN_layer_nodes']\n",
    "        CNN_kernel_size   = self.pams['CNN_kernel_size']\n",
    "        CNN_pool          = self.pams['CNN_pool']\n",
    "        Dense_layer_nodes = self.pams['Dense_layer_nodes'] #does not include encoded layer\n",
    "        channels_first    = self.pams['channels_first']\n",
    "\n",
    "        # fix to one cnn layer for now\n",
    "        nnodes=CNN_layer_nodes[0] #8\n",
    "        depth_multiplier = CNN_layer_nodes[0]\n",
    "        CNN_kernel=CNN_kernel_size[0] #3\n",
    "\n",
    "        inputs = Input(shape=self.pams['shape'])\n",
    "        x = inputs\n",
    "\n",
    "        x = DepthwiseConv2D(CNN_kernel, padding='same', activation='relu',depth_multiplier=depth_multiplier)(x)\n",
    "\n",
    "        shape = K.int_shape(x)\n",
    "        #print(\"KINT SHAPE\",shape)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        encodedLayer = Dense(encoded_dim, activation='relu',name='encoded_vector')(x)\n",
    "\n",
    "        # Instantiate Encoder Model\n",
    "        self.encoder = Model(inputs, encodedLayer, name='encoder')\n",
    "        if printSummary:\n",
    "          self.encoder.summary()\n",
    "          plot_model(self.encoder, show_shapes=True, to_file=\"model1.png\")\n",
    "\n",
    "        encoded_inputs = Input(shape=(encoded_dim,), name='decoder_input')\n",
    "        x = encoded_inputs\n",
    "\n",
    "        x = Dense(shape[1]*shape[2]*shape[3], activation='relu')(x)\n",
    "\n",
    "        x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "        \n",
    "        x = Conv2DTranspose(self.pams['shape'][2], CNN_kernel_size[0], activation='relu', padding='same')(x)\n",
    "\n",
    "        outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "\n",
    "        self.decoder = Model(encoded_inputs, outputs, name='decoder')\n",
    "        if printSummary:\n",
    "          self.decoder.summary()\n",
    "          plot_model(self.decoder, show_shapes=True, to_file=\"model2.png\")\n",
    "\n",
    "        self.autoencoder = Model(inputs, self.decoder(self.encoder(inputs)), name='autoencoder')\n",
    "        if printSummary:\n",
    "          self.autoencoder.summary()\n",
    "          plot_model(self.autoencoder, show_shapes=True, to_file=\"model.png\")\n",
    "\n",
    "        if self.pams['loss']==\"weightedMSE\":\n",
    "            self.autoencoder.compile(loss=self.weightedMSE, optimizer='adam')\n",
    "            self.encoder.compile(loss=self.weightedMSE, optimizer='adam')\n",
    "        elif self.pams['loss'] == 'telescopeMSE':\n",
    "           self.autoencoder.compile(loss=telescopeMSE2, optimizer='adam', run_eagerly=True)\n",
    "           self.encoder.compile(loss=telescopeMSE2, optimizer='adam', run_eagerly=True)\n",
    "        elif self.pams['loss']!='':\n",
    "            self.autoencoder.compile(loss=self.pams['loss'], optimizer='adam')\n",
    "            self.encoder.compile(loss=self.pams['loss'], optimizer='adam')\n",
    "        else:\n",
    "            self.autoencoder.compile(loss='mse', optimizer='adam')\n",
    "            self.encoder.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "        CNN_layers=''\n",
    "        if len(CNN_layer_nodes)>0:\n",
    "            CNN_layers += '_Conv'\n",
    "            for i,n in enumerate(CNN_layer_nodes):\n",
    "                CNN_layers += f'_{n}x{CNN_kernel_size[i]}'\n",
    "                if CNN_pool[i]:\n",
    "                    CNN_layers += 'pooled'\n",
    "        Dense_layers = ''\n",
    "        if len(Dense_layer_nodes)>0:\n",
    "            Dense_layers += '_Dense'\n",
    "            for n in Dense_layer_nodes:\n",
    "                Dense_layers += f'_{n}'\n",
    "\n",
    "        self.name = f'Autoencoded{CNN_layers}{Dense_layers}_Encoded_{encoded_dim}'\n",
    "        \n",
    "        if not self.weights_f=='':\n",
    "            self.autoencoder.load_weights(self.weights_f)\n",
    "    def get_models(self):\n",
    "       return self.autoencoder,self.encoder\n",
    "           \n",
    "    def predict(self,x):\n",
    "        decoded_Q = self.autoencoder.predict(x)\n",
    "        encoded_Q = self.encoder.predict(x)\n",
    "        s = self.pams['shape'] \n",
    "        if self.pams['channels_first']:\n",
    "            shaped_x  = np.reshape(x,(len(x),s[0]*s[1],s[2]))\n",
    "            decoded_Q = np.reshape(decoded_Q,(len(decoded_Q),s[0]*s[1],s[2]))\n",
    "            encoded_Q = np.reshape(encoded_Q,(len(encoded_Q),self.pams['encoded_dim'],1))\n",
    "        else:\n",
    "            shaped_x  = np.reshape(x,(len(x),s[2]*s[1],s[0]))\n",
    "            decoded_Q = np.reshape(decoded_Q,(len(decoded_Q),s[2]*s[1],s[0]))\n",
    "            encoded_Q = np.reshape(encoded_Q,(len(encoded_Q),self.pams['encoded_dim'],1))\n",
    "        return shaped_x,decoded_Q, encoded_Q\n",
    "\n",
    "    def summary(self):\n",
    "      self.encoder.summary()\n",
    "      self.decoder.summary()\n",
    "      self.autoencoder.summary()\n",
    "\n",
    "    ##get pams for writing json\n",
    "    def get_pams(self):\n",
    "      jsonpams={}\n",
    "      for k,v in self.pams.items():\n",
    "          if type(v)==type(np.array([])):\n",
    "              jsonpams[k] = v.tolist()\n",
    "          else:\n",
    "              jsonpams[k] = v \n",
    "      return jsonpams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = denseSepConv2D()\n",
    "m.init(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_autoCNN, m_autoCNNen = m.get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_autoCNN.layers[2].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_decoder = Model(inputs = m_autoCNN.layers[2].input,\n",
    "                 outputs = m_autoCNN.layers[2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_autoCNNen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_autoCNNen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "total model\n",
      "------------\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4, 4, 3)]         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                1632      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 4, 4, 3)           1705      \n",
      "=================================================================\n",
      "Total params: 3,337\n",
      "Trainable params: 3,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "------------\n",
      "encoder\n",
      "------------\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4, 4, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4, 4, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 4, 4, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 2, 2, 8)      80          lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 32)           0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 32)           0           conv2d_1[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           conv2d_1[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_1 (Concatenate)          (None, 96)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoded_vector (Dense)          (None, 16)           1552        concat_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,632\n",
      "Trainable params: 1,632\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "------------\n",
      "decoder\n",
      "------------\n",
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 96)           1632        decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2, 2, 8, 3)   0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2, 2, 8)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 2, 2, 8)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2, 2, 8)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 1)      73          lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_2 (Concatenate)          (None, 4, 4, 3)      0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_transpose_1[1][0]         \n",
      "                                                                 conv2d_transpose_1[2][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Activation)     (None, 4, 4, 3)      0           concat_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,705\n",
      "Trainable params: 1,705\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "edim = 16\n",
    "arrange443 = np.array([0,16, 32,\n",
    "                       1,17, 33,\n",
    "                       2,18, 34,\n",
    "                       3,19, 35,\n",
    "                       4,20, 36,\n",
    "                       5,21, 37,\n",
    "                       6,22, 38,\n",
    "                       7,23, 39,\n",
    "                       8,24, 40,\n",
    "                       9,25, 41,\n",
    "                       10,26, 42,\n",
    "                       11,27, 43,\n",
    "                       12,28, 44,\n",
    "                       13,29, 45,\n",
    "                       14,30, 46,\n",
    "                       15,31, 47])\n",
    "nBits_encod_total = 7\n",
    "model_config =  {\n",
    "        'name': \"Aug14_qKeras_optA\", 'ws': '', # custom\n",
    "        'pams': {'shape': (4, 4, 3),                                                                                                  \n",
    "                 'channels_first': False,                                                                                             \n",
    "                 'arrange': arrange443,\n",
    "                 'encoded_dim': edim,                                                                                                 \n",
    "                 'loss': 'weightedMSE',                                                                                              \n",
    "                 'nBits_encod'  : {'total':  nBits_encod_total, 'integer': 1,'keep_negative':0},                                      \n",
    "                 'nBits_input'  : {'total': 10,                 'integer': 3,'keep_negative':1},                                      \n",
    "                 'nBits_accum'  : {'total': 11,                 'integer': 3,'keep_negative':1},                                      \n",
    "                 'nBits_weight' : {'total':  5,                 'integer': 1,'keep_negative':1},                                      \n",
    "             },\n",
    "         'isQK':False,\n",
    "        }\n",
    "m = dense2DkernelCNN()\n",
    "m.setpams(model_config['pams'])\n",
    "m.init(False)\n",
    "m_autoCNN, m_autoCNNen = m.get_models()\n",
    "\n",
    "print('------------\\ntotal model\\n------------')\n",
    "print(m_autoCNN.summary())\n",
    "print('------------\\nencoder\\n------------')\n",
    "print(m_autoCNNen.summary())\n",
    "print('------------\\ndecoder\\n------------')\n",
    "print(m_autoCNN.layers[2].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_raw = '../SampleSplitting_SignalAllocation/nElinks_5/ttbar_v11_eolNoise_Layer9_5Links.csv'\n",
    "calQ     = np.genfromtxt(f_raw, delimiter=',',usecols=[*range(0, 48)],skip_header=2000,max_rows=10000)\n",
    "sumQ     = calQ.sum(axis=1)\n",
    "calQ     = calQ[sumQ>0]\n",
    "sumQ     = sumQ[sumQ>0]\n",
    "\n",
    "inputQf_48_arr   = np.array([calQ[i]/s for i,s in enumerate(sumQ)])[:,arrange443]  \n",
    "inputQf_443_arr  = inputQf_48_arr.reshape(len(inputQf_48_arr),4,4,3)\n",
    "inputQ_48_arr    = np.array([inputQf_48_arr[i]*s for i,s in enumerate(sumQ)])              \n",
    "inputQ_443_arr   =  inputQ_48_arr.reshape(len(inputQ_48_arr),4,4,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8932 samples\n",
      "Epoch 1/10\n",
      "8932/8932 [==============================] - 20s 2ms/sample - loss: 85.2570\n",
      "Epoch 2/10\n",
      "8932/8932 [==============================] - 18s 2ms/sample - loss: 0.2022\n",
      "Epoch 3/10\n",
      "8932/8932 [==============================] - 19s 2ms/sample - loss: 0.1634\n",
      "Epoch 4/10\n",
      "8932/8932 [==============================] - 18s 2ms/sample - loss: 0.1588\n",
      "Epoch 5/10\n",
      "8932/8932 [==============================] - 15s 2ms/sample - loss: 0.1571\n",
      "Epoch 6/10\n",
      "8932/8932 [==============================] - 13s 2ms/sample - loss: 0.1555\n",
      "Epoch 7/10\n",
      "8932/8932 [==============================] - 16s 2ms/sample - loss: 0.1529\n",
      "Epoch 8/10\n",
      "8932/8932 [==============================] - 17s 2ms/sample - loss: 0.1490\n",
      "Epoch 9/10\n",
      "8932/8932 [==============================] - 16s 2ms/sample - loss: 0.1417\n",
      "Epoch 10/10\n",
      "8932/8932 [==============================] - 17s 2ms/sample - loss: 0.1350\n"
     ]
    }
   ],
   "source": [
    "history = m_autoCNN.fit(inputQf_443_arr,\n",
    "                        inputQf_443_arr,\n",
    "                        epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff45ad70ad0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n",
    "\n",
    "# check agreement with one sample:\n",
    "plt.figure()\n",
    "plt.imshow(inputQf_443_arr[0,:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(m_autoCNN(inputQf_443_arr[0:1])[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

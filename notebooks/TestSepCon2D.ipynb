{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from dense2DkernelCNN import dense2DkernelCNN \n",
    "from denseCNN import denseCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4, 4, 3)]         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 8)           224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "encoded_vector (Dense)       (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 620\n",
      "Trainable params: 620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 12)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                416       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 2, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 4, 4, 3)           219       \n",
      "_________________________________________________________________\n",
      "decoder_output (Activation)  (None, 4, 4, 3)           0         \n",
      "=================================================================\n",
      "Total params: 1,219\n",
      "Trainable params: 1,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4, 4, 3)]         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 12)                620       \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 4, 4, 3)           1219      \n",
      "=================================================================\n",
      "Total params: 1,839\n",
      "Trainable params: 1,839\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = denseCNN()\n",
    "m.setpams({'CNN_pool':[True],'shape': (4, 4, 3)})\n",
    "m.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 4, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4, 4, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4, 4, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 4, 4, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 4, 4, 8)      80          lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 4, 4, 8)      80          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 4, 4, 8)      80          lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 128)          0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 128)          0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_1 (Concatenate)          (None, 384)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoded_vector (Dense)          (None, 16)           6160        concat_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,400\n",
      "Trainable params: 6,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 384)          6528        decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 4, 4, 8, 3)   0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 4, 4, 8)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 4, 4, 8)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 4, 4, 8)      0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 4, 4, 1)      73          lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_2 (Concatenate)          (None, 4, 4, 3)      0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_transpose_1[1][0]         \n",
      "                                                                 conv2d_transpose_1[2][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Activation)     (None, 4, 4, 3)      0           concat_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 6,601\n",
      "Trainable params: 6,601\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4, 4, 3)]         0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 16)                6400      \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 4, 4, 3)           6601      \n",
      "=================================================================\n",
      "Total params: 13,001\n",
      "Trainable params: 13,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m = dense2DkernelCNN()\n",
    "m.setpams({'encoded_dim':16,'share_filters':False})\n",
    "m.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_autoCNN, m_autoCNNen = m.get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_autoCNN.layers[2].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_decoder = Model(inputs = m_autoCNN.layers[2].input,\n",
    "                 outputs = m_autoCNN.layers[2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_autoCNNen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_autoCNNen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m           values = ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m    464\u001b[0m               \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   1289\u001b[0m           \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'loss/decoder_loss/MatMul/b:0' shape=(48, 36) dtype=float32>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-45e2aea77ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense2DkernelCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetpams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pams'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mm_autoCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_autoCNNen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uscms_data/d3/kkwok/HGC/CMSSW_11_1_0_pre6/src/Ecoder/dense2DkernelCNN.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, printSummary)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweightedMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'telescopeMSE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtelescopeMSE2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtelescopeMSE2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m       \u001b[0;31m# Creates the model loss and weighted metrics sub-graphs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m       \u001b[0;31m# Functions for train, test and predict will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self, sample_weights)\u001b[0m\n\u001b[1;32m   1590\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reduction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             \u001b[0mper_sample_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m             weighted_losses = losses_utils.compute_weighted_loss(\n\u001b[1;32m   1654\u001b[0m                 \u001b[0mper_sample_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    219\u001b[0m       y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n\u001b[1;32m    220\u001b[0m           y_pred, y_true)\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uscms_data/d3/kkwok/HGC/CMSSW_11_1_0_pre6/src/Ecoder/telescope.py\u001b[0m in \u001b[0;36mtelescopeMSE2\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# map TCs to 2x2 supercells and compute MSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0my_pred_36\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_rs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_Remap_48_36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0my_true_36\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true_rs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_Remap_48_36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# lossTC2 = K.mean(K.square(y_true_12 - y_pred_12), axis=(-1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2795\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2796\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2797\u001b[0;31m       return gen_math_ops.mat_mul(\n\u001b[0m\u001b[1;32m   2798\u001b[0m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[1;32m   2799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5622\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5623\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5624\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5625\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5626\u001b[0m                   name=name)\n",
      "\u001b[0;32m/cvmfs/cms.cern.ch/slc7_amd64_gcc820/external/py3-tensorflow/2.1.0-bcolbf2/lib/python3.8/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    499\u001b[0m                   \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Default in OpDef\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    502\u001b[0m                 \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                 (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'."
     ]
    }
   ],
   "source": [
    "edim = 16\n",
    "arrange443 = np.array([0,16, 32,\n",
    "                       1,17, 33,\n",
    "                       2,18, 34,\n",
    "                       3,19, 35,\n",
    "                       4,20, 36,\n",
    "                       5,21, 37,\n",
    "                       6,22, 38,\n",
    "                       7,23, 39,\n",
    "                       8,24, 40,\n",
    "                       9,25, 41,\n",
    "                       10,26, 42,\n",
    "                       11,27, 43,\n",
    "                       12,28, 44,\n",
    "                       13,29, 45,\n",
    "                       14,30, 46,\n",
    "                       15,31, 47])\n",
    "nBits_encod_total = 7\n",
    "model_config =  {\n",
    "        'name': \"Aug14_qKeras_optA\", 'ws': '', # custom\n",
    "        'pams': {'shape': (4, 4, 3),    \n",
    "                 'CNN_pool':[1],\n",
    "                 'channels_first': False,                                                                                             \n",
    "                 'arrange': arrange443,\n",
    "                 'encoded_dim': edim,                                                                                                 \n",
    "                 'loss': 'telescopeMSE',                                                                                              \n",
    "                 'nBits_encod'  : {'total':  nBits_encod_total, 'integer': 1,'keep_negative':0},                                      \n",
    "                 'nBits_input'  : {'total': 10,                 'integer': 3,'keep_negative':1},                                      \n",
    "                 'nBits_accum'  : {'total': 11,                 'integer': 3,'keep_negative':1},                                      \n",
    "                 'nBits_weight' : {'total':  5,                 'integer': 1,'keep_negative':1},                                      \n",
    "             },\n",
    "         'isQK':False,\n",
    "        }\n",
    "m = dense2DkernelCNN()\n",
    "m.setpams(model_config['pams'])\n",
    "m.init(False)\n",
    "m_autoCNN, m_autoCNNen = m.get_models()\n",
    "\n",
    "print('------------\\ntotal model\\n------------')\n",
    "print(m_autoCNN.summary())\n",
    "print('------------\\nencoder\\n------------')\n",
    "print(m_autoCNNen.summary())\n",
    "print('------------\\ndecoder\\n------------')\n",
    "print(m_autoCNN.layers[2].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_raw = '../SampleSplitting_SignalAllocation/nElinks_5/ttbar_v11_eolNoise_Layer9_5Links.csv'\n",
    "calQ     = np.genfromtxt(f_raw, delimiter=',',usecols=[*range(0, 48)],skip_header=2000,max_rows=10000)\n",
    "sumQ     = calQ.sum(axis=1)\n",
    "calQ     = calQ[sumQ>0]\n",
    "sumQ     = sumQ[sumQ>0]\n",
    "\n",
    "inputQf_48_arr   = np.array([calQ[i]/s for i,s in enumerate(sumQ)])[:,arrange443]  \n",
    "inputQf_443_arr  = inputQf_48_arr.reshape(len(inputQf_48_arr),4,4,3)\n",
    "inputQ_48_arr    = np.array([inputQf_48_arr[i]*s for i,s in enumerate(sumQ)])              \n",
    "inputQ_443_arr   =  inputQ_48_arr.reshape(len(inputQ_48_arr),4,4,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8932 samples\n",
      "Epoch 1/10\n",
      "8932/8932 [==============================] - 2s 231us/sample - loss: 0.0252\n",
      "Epoch 2/10\n",
      "8932/8932 [==============================] - 1s 92us/sample - loss: 0.0074\n",
      "Epoch 3/10\n",
      "8932/8932 [==============================] - 1s 88us/sample - loss: 0.0069\n",
      "Epoch 4/10\n",
      "8932/8932 [==============================] - 1s 86us/sample - loss: 0.0058\n",
      "Epoch 5/10\n",
      "8932/8932 [==============================] - 1s 87us/sample - loss: 0.0040\n",
      "Epoch 6/10\n",
      "8932/8932 [==============================] - 1s 85us/sample - loss: 0.0024\n",
      "Epoch 7/10\n",
      "8932/8932 [==============================] - 1s 88us/sample - loss: 0.0015\n",
      "Epoch 8/10\n",
      "8932/8932 [==============================] - 1s 90us/sample - loss: 0.0011\n",
      "Epoch 9/10\n",
      "8932/8932 [==============================] - 1s 87us/sample - loss: 9.0786e-04\n",
      "Epoch 10/10\n",
      "8932/8932 [==============================] - 1s 85us/sample - loss: 7.9055e-04\n"
     ]
    }
   ],
   "source": [
    "history = m_autoCNN.fit(inputQf_443_arr,\n",
    "                        inputQf_443_arr,\n",
    "                        epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f424d75a820>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAD8CAYAAAB6iWHJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOPUlEQVR4nO3d78/ddX3H8efrlAthxa0uiHQXHbisM1ETlV2pGJOF+WOBhqzeMAtmEWOWNBo1usxkZEtcvOctkyEKa6ZREqMzQR1xdYYZjJqNH5UUtCBb48y4UiYKAhbIWPG1G3SWttfVHvie6/q2h+fjDyjnnKvvZ9+fcx3OJ22RpGNNkCTjIMnNQZLHCkmDOmAcJBkHSQM3hzMYIMlvAv8AXAT8GPiTtj/nGEl+DPwCeBo41HYJSQPHd21NBtblauCbbbcC3wSuZnV/2Pa1bZeQNPbsn9TQOOwAPsczPge8DUljz/VMpC3PV5JH2m76/+Uoyc/bvuTYZSnJfwI/Bwr8XdtdrCLJTmAnQM488/cXzjuPeTM5xNx61Xk/ZR491aeZR8vLT/Pww78MKziDk0jyL8D5HO+vmd4b2x5Ich5wc5Iftv02K2i7C9gF8KItW7r4oT9n3rzo4TCvbv/Ap5hH/3XoIPPoj7f/jNWcwUm0fQurSPKTJJvbPpBkM/AgK2h7AKDtg0m+AmwDvo2ksU8Pqxr6nsNNwLt4xruAf+QYSTYmeTFAko3AHwE/QNLY839CQ+PwMeCtSf4DeCvwMYAkv5VkN894GfDdJHcBtwP/1PafkTT2/J/QoM85tH0IeDPHaHsA2A7Q9kfAa5A09rw/J0M3B0ljT/EamczrE5NkHCTNYlUwDpKMgyQ3B0nPuwPGQZJxkOTmIGlgB4yDJOMgyc1B0sAOGAdJxkGSm4OkgR0wDpKMgyQ3B0kDO7B2cUhyWZL7kuxPcjXHSJIk1yTZn+TuJBcjaS1memYGxyHJBuCTwOXAK4F3JHklR7sc2ApsBXYC1yFp3Ok/icFxALYB+9v+qO1TwBeBHRxtB3BD27a9FdiUZDOSxm7AqmYRh0Xgfo5YBhY52iJwP0csA4sz+G9LOoXjEI5XjhaO1xX/sGRnkj1J9jz9+ONIWqPpX4c4LANbOOIC4MAxF18tA1s44gLgwEp/WNtdbZfaLm3YuBFJp28c7gC2Jnl5kjOBK4GbONpNwFVJkuQS4NG2D8zHReXSOMO71gbdeHX41qtDSd4PfAPYAHym7b4k7wFoez2wG9gO7AeeAN6NpLHn/4QGx+FwIHYDu591tKDt9RzWtsD7kDT2zE9tFscKSWNP8hqYzOOTkmQcJA3vgHGQZBwkuTlIGtgB4yDJOEhyc5A0sAPGQZJxkOTmIGlgB4yDJOMgyc1B0sAOGAdJxkGSm4OkgR0wDpLWOQ5JLktyX5L9Sa7mGEkuTfJokr1J9ib5CJLW4h/8mRn8BbNJNgCfBN4KLAN3JLmp7T0c7Tttr0DS2HM/lcFxALYB+9v+CCDJF4EdwD0MdNZP/5ff2/UT5s7DjzCvPv6nv8M8uu+JlzGPHjj0T6xmwnCLwP0csQwscrw3JLkrydeTvIpVJNmZZE+SPU89/SSSTt/NIRyvHO1O4MK2B5NsB74KbGUFbXcBuwB+46zzi6RR4jCLNyRPeldm28faHgRouxtYSHIukkYZ/GnMIg4nvSszyflJApBkGzABHkLS2A1Y1eBjxZR3Zb4deG+SQ8CTwJVtu8JxRNLYVThscBwOB+Jkd2VeC1yLpLFnfmqzOFZIGnuS18BkHp+UJOMgaXgHjIMk4yDJzUHSwA4YB0nGQZKbg6SBHTAOkoyDJDcHSQM7YBwkGQdJbg6SBnbAOEgyDpLcHCQN7MDaxSHJZ5I8mOQHrCBJklyTZH+Su5NcjKS1mOmZmUkcgM8Cl7G6y4GtwFZgJ3Adksae/xOaSRzafht4mNXtAG5o27a3ApuSbEbS2A1Y1UziMIVF4P5n3YC1DCyu9BXcSXYm2ZNkz1NPP4mk+Y5DVuhjV3pAbXe1XWq7dOaGs5G0rk34lfWKw0mvzJM0TgRWs15xuAm4KkmSXAI82vYBJI3dgFXN5MarJF8ALgXOTbIM/A2wAND2emA3sB3YDzwBvBtJY8//Cc0kDm3fwQm0LfA+JI0981Nbr2OFpLGn/TmanG4PWJJxkLQ+HTAOkoyDJDcHSQM7YBwkGQdJbg6SBnbAOEgyDpLcHCQN7IBxkGQcJLk5SBrYAeMgyThIcnOQNLADaxeHKa7DuzTJo0n2Jtmb5CNIWouZnpmZfIck8FngWuCGE9y/8Z22VyBp7Lmfykw2hymuw5M09rQ/R7PaHKbxhiR3AQeAD7fdxwqS7AR2Aiyc8xL++80vY94c+rXzmVefuutC5tFZ3z+beXTw57ewmgnr407gwravAT4BfJVVtN3Vdqnt0hlnb0TSOJvDTI4VUxw7Hmt7EKDtbmAhyblIGmfyp7AucUhyfpIAJNkGTICHkDR2A1Y1k/ccprgO7+3Ae5McAp4ErmxbJI3dgFXNJA5TXId3LXDtqbtAjf1jkE4963KskDT2qD93k9PwMUsyDpLWoQPGQZJxkOTmIGlgB4yDJOMgyc1B0sAOGAdJxkGSm4OkgR0wDpKMgyQ3B0kDO2AcJBkHSW4OkgZ2YG3ikGRLkluS3JtkX5IPcowkSXJNkv1J7k5yMZLWYqZnZhbfIXkI+Iu2dyZ5MfC9JDe3vYcjLge2AluB1wPXAa9H0tgNWNXgzaHtA23vBGj7C+BeYJGj7QBuaNu2twKbkmxG0tgNWNXgODxbkouA1wG3cbRF4H6OWAYWWUGSnUn2JNlz6MnHkXSaxyHJOcCNwIfaPsbRwvHKCtruarvUdumMszci6TSOQ5IF4Ebg822/zPGWgS0ccQFwAEnjTP4UBschSYBPA/e2/fgqJ6ibgKuSJMklwKNtH0DS2A1Y1Sx+W/FG4J3A95Ps5Rl/Bfw2QNvrgd3AdmA/8ATwbiSNPf8nNDgObb8LhBNoW+B9SBp75qc2+FghaewxXhuTOX1ekoyDpBksCsZBa/HXSPNo4t8VScZBkpuDJI8VkoZ1wDhIMg6S3BwkDeyAcZBkHCS5OUga2AHjIMk4SHJzkDSwA8ZB0jrGYcrr8C5N8miSvUn2JvnIuj1DSc9rcxj8HZIw1XV4AN9pewWSntewrrfJ0LpMeR2epLGn/TmaxebwK0kuAl4H3Mbx3pDkLuAA8OG2+1hBkp3AToAzNr2EX7yc+ZMyry76+zCPNtzyr8yj5T7OaibMSJJzgBuBD7V9jKPdCVzY9jXAJ4Cvsoq2u9outV2abNyIpHE2h8HHCuCk1+G1faztQYC2u4GFJOeO85QlTWNwHKa5Di/J+UkCkGQbMAEeQtLYDVjVLN5zmOY6vLcD701yCHgSuLJtkTR2A1Y1OA5TXod3LXAtksae+akNPlZIGnuM18ZkTp+XJOMgaQaLgnGQZBwkuTlIGtAB4yDJOEiz/of0BWfiSyjJOEhyc5DksULSsA4YB0nGQZKbg6SBHTAOkoyDJDcHSQM7sDZxSHJWktuT3JVkX5KPcowkSXJNkv1J7k5yMZLWYqZnZvB3SAL/A7yp7cEkC8B3k3y97a0ccTmwFdgKvB64Dng9ksZuwKoGbw5t2/Ygz1gAFoBytB3ADW3b9lZgU5LNSBq7AasaHAeAJBuS7AUeBG5uextHWwTu54hlYBFJYzdgVTOJQ9un274WuADYluTVHC0cr6wgyc4ke5Ls+eXjjyPpNI7DsyLxCPAt4DKOtgxs4YgLgAOsoO2utkttlyYbNyLpNI1Dkpcm2QSQ5GzgLcAPOdpNwFVJkuQS4NG2D4xdRkmrx2EWv63YDHwuyQZgAnyp7deSvAeg7fXAbmA7sB94Ang3ktZrCXheBseh7d3A6zhG2+s5rG2B9yFp7Jmf2uBjhaSxx3htTOb0eUkyDpJmsCgYB0nGQZKbg6QBHTAOkoyDJDcHSQM7YBwkGQdJbg7SwCnQiia+rpKMgyQ3B0keKyQN64BxkGQcJLk5SBrYgbWJw5R3ZV6a5NEke5PsTfIRJK3FTM/M4C+YhanuygT4TtsrkDT23E9lcBzaFjjIMxaABaBIGnu+B0lbhkqyAfge8LvAJ9v+Jc+S5FLgRmAZOAB8uO0+VpBkJ7CTZ7wCuI/1cS7wM+bPucDP1uk1XE/z+vMCOBf4GevjwrYvZQVpy6wk2QR8BfhA2x9wWJJfB37Z9mCS7cDftt3KKSTJnrZLzJkke9oujf36ztq8/rwAkuxpu8TIJkOPFcccMR4BvgVcxrO0faztQYC2u4GFJOciaaxTw0nN4rcVJ70rM8n5SQKQZBswAR5C0tgNWNUZM1gYprkr8+3Ae5McAp4ErmxbTi27mE+7xn5h18iusV/YNZzLXZwC0hZJOrZQg48VktZwhxjRZE6flyTjMEySy5Lcl2R/kquZE0k+k+TBJD9gjiTZkuSWJPcm2Zfkg8yBJGcluT3JXUn2JfkoI0vblT6L9IKQZAPw78BbgWXgDuAdbe/hNJfkD4CDwA1tX82cSLIZ2Nz2ziQvPvzhu7e1vYfTWJIAG9seTLIAfBf4YNtbGclk7HdER7YN2N/2R22fAr4I7GAOtP028DBzpu0Dbe8EaPsL4F5gkdNc27Y9ePhzgwvAAlBGNOGFbRG4nyOWgcWxP/2n6SS5CHgdcBtzIMmGJHuBB4Gb297GiCa8sIXjdewVUyeX5BzgRuBDbR9jDrR9uu1rgQuAbUlezYgmvLAtA1s44gLgADqlJVkAbgQ+3/bLY79JOvRXhsdq+wjwLeAyRjQ5Pf7P8jVzB7A1ycuTnAlcCdw09sfjtLokAT4N3Nv248yJJC9NsgkgydnAW4AfMqIJL2BtDwHvB75x+I2tL7XdxxxI8gXg34BXJFlO8mfMhzcC7wTelGRvkr1JtnP62wzckuRu4A7g5rZfY0RpiyT5IShJU733MRn7AUia4buZMzQ5RR+XJOMgaeQOrGhySj4qSWO3wThIMg6SnoP/A1WtKC76RRUdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # check loss\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.show()\n",
    "\n",
    "# check agreement with one sample:\n",
    "plt.figure()\n",
    "plt.imshow(inputQf_443_arr[0,:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(m_autoCNN(inputQf_443_arr[0:1])[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
